\chapter{INTRODUCCIÓN}

\section{Propósito}

El presente documento tiene como propósito especificar de manera detallada los requerimientos funcionales y no funcionales del sistema denominado Observatorio de Demanda Laboral en Tecnología en Latinoamérica, una herramienta de análisis automatizado orientada a procesar, extraer y segmentar habilidades tecnológicas desde portales de empleo en línea, mediante técnicas modernas de procesamiento de lenguaje natural (NLP), scraping, embeddings semánticos y clustering no supervisado.

Este documento está dirigido principalmente a los siguientes públicos:

\begin{itemize}
    \item El equipo de desarrollo del proyecto, compuesto por los estudiantes \autorUno{} y  \autorDos{}, como guía estructurada para la implementación y validación del sistema.

    \item El director del proyecto, \director{}, y los jurados evaluadores, como evidencia formal del entendimiento técnico y conceptual del producto a desarrollar.

    \item Otros actores académicos o institucionales interesados en replicar o adaptar el sistema en contextos similares, como universidades, centros de investigación o entidades públicas vinculadas al análisis del mercado laboral.
\end{itemize}

El documento cubre la totalidad del sistema propuesto, sin limitarse a un solo módulo o subsistema. Por tanto, especifica requerimientos relacionados con la adquisición de datos (scraping), su procesamiento semántico, análisis estadístico y segmentación por perfiles laborales, así como aspectos de validación, modularidad, documentación técnica y estándares de calidad.

La importancia de este documento radica en su papel como contrato técnico entre los actores involucrados, asegurando una visión compartida del comportamiento esperado del sistema, las restricciones existentes, los criterios de aceptación y los estándares metodológicos adoptados. Además, facilita la trazabilidad entre los objetivos definidos en la propuesta de grado y las funcionalidades implementadas en cada fase, garantizando coherencia metodológica, control de calidad y sostenibilidad del desarrollo.

\section{Alcance}

El sistema propuesto, titulado Observatorio de Demanda Laboral en Tecnología en Latinoamérica, tiene como propósito desarrollar una herramienta automatizada capaz de analizar la evolución de las habilidades tecnológicas demandadas en el mercado laboral digital, específicamente en los países de Colombia (CO), México (MX) y Argentina (AR). El sistema abarca desde la recolección periódica de datos a través de scraping en portales de empleo hasta el procesamiento semántico y la segmentación de perfiles laborales utilizando técnicas avanzadas de NLP y clustering no supervisado.

Alcance geográfico: Colombia (CO), México (MX), Argentina (AR)

Fuentes de datos: 8 portales de empleo principales incluyendo hiring.cafe, computrabajo, bumeran, elempleo.com, zonajobs, indeed, magneto y occ mundial.

Taxonomía base: El sistema utiliza una taxonomía unificada de 14,215 skills totales, compuesta por:
\begin{itemize}
    \item ESCO v1.1.0: 13,939 skills (base europea de competencias laborales)
    \item O*NET Hot Technologies: 152 skills (tecnologías emergentes del sector IT)
    \item Manual Curated Skills: 124 skills (específicas para el mercado tech latinoamericano)
\end{itemize}

Stack tecnológico: Python 3.10+, Scrapy, spaCy, PostgreSQL, FAISS, embeddings E5 multilingües (intfloat/multilingual-e5-base, 768D), HDBSCAN, UMAP.

El producto incluirá las siguientes funcionalidades principales:

\begin{itemize}
    \item Extracción automatizada de vacantes desde 8 portales web principales, mediante spiders adaptables que operan respetando las normas de uso de cada sitio.

    \item Procesamiento y limpieza textual, incluyendo tokenización, lematización y detección de habilidades explícitas mediante técnicas híbridas de NER, expresiones regulares y modelos de lenguaje.

    \item Representación semántica de habilidades mediante embeddings multilingües (modelo E5 de 768 dimensiones) y reducción de dimensionalidad (UMAP).

    \item Mapeo de habilidades contra taxonomía ESCO mediante estrategia de tres capas: matching exacto, fuzzy matching y semantic matching con FAISS.

    \item Agrupamiento de perfiles mediante algoritmos robustos como HDBSCAN, que permitan segmentar la demanda en grupos funcionales coherentes.

    \item Visualización macro de resultados a través de gráficos interpretables y reportes estáticos que permitan identificar patrones emergentes sin requerir dashboards interactivos.

    \item Documentación metodológica y código reproducible, que permitan replicar o adaptar el sistema a otras regiones o sectores, bajo principios de ética, apertura y eficiencia computacional.
\end{itemize}

Este sistema no contempla el desarrollo de una interfaz web pública ni funcionalidades de tipo portal o dashboard interactivo, sino que prioriza la generación de reportes analíticos estáticos y reutilizables, como producto de validación académica y técnica.

El alcance funcional se circunscribe al dominio de las ofertas de empleo tecnológicas publicadas en español en los países mencionados, sin contemplar vacantes en otros idiomas ni otros sectores económicos. Sin embargo, el diseño modular del sistema permitirá su adaptación futura a nuevos contextos geográficos o temáticos.

\section{Definiciones, Acrónimos y Abreviaciones}

\subsection{Portales de empleo}
Son plataformas web donde empresas publican vacantes laborales y profesionales buscan oportunidades. En este proyecto se consideran fuentes como LinkedIn, Computrabajo, Bumeran, ZonaJobs e Indeed, que constituyen insumos primarios para los procesos de scraping y análisis \cite{aguilera2018, cardenas2015}.

\subsection{Web Scraping}
Técnica de recolección automatizada de datos desde páginas web, utilizando librerías como BeautifulSoup, Selenium o Playwright. Permite extraer de forma estructurada información relevante de las ofertas publicadas \cite{orozco2019}.

\subsection{Oferta laboral}
Se refiere al anuncio publicado por una organización donde se describe el perfil buscado, incluyendo título del cargo, funciones, requisitos y habilidades deseadas \cite{rubio2024}.

\subsection{Base de datos relacional (PostgreSQL)}
Sistema que organiza los datos recolectados en tablas interconectadas, facilitando su consulta, limpieza y posterior análisis mediante estructuras SQL \cite{martinez2024}.

\subsection{Normalización de datos}
Proceso de limpieza, estandarización y unificación de formatos para reducir ambigüedad, errores y duplicados, y mejorar la coherencia del análisis posterior \cite{martinez2024}.

\subsection{Expresiones regulares (Regex)}
Lenguaje sintáctico utilizado para identificar y extraer patrones textuales específicos (como frases que contengan habilidades o requisitos) en grandes volúmenes de texto.

\subsection{Named Entity Recognition (NER)}
Técnica de procesamiento de lenguaje natural (NLP) que identifica y clasifica entidades en un texto, como nombres de habilidades, empresas o tecnologías \cite{vasquez2024, aitoskillner}.

\subsection{Tokenización}
Consiste en dividir un texto en unidades mínimas llamadas ``tokens'' (palabras, signos u oraciones), facilitando el análisis lingüístico automatizado.

\subsection{Lematización}
Proceso que transforma las palabras a su forma canónica o raíz gramatical, permitiendo uniformar variaciones morfológicas del lenguaje.

\subsection{Stopwords}
Términos frecuentes sin valor informativo (como ``de'', ``por'', ``la''), comúnmente eliminados en tareas de procesamiento textual.

\subsection{Co-ocurrencia}
Medida estadística que indica la frecuencia con que dos o más términos aparecen juntos en un texto, útil para detectar relaciones semánticas \cite{lukauskas2023}.

\subsection{Bigramas y trigramas}
Secuencias de dos o tres palabras consecutivas utilizadas para capturar patrones de lenguaje más complejos que las palabras individuales.

\subsection{LLM (Large Language Models)}
Modelos de lenguaje de gran escala (como GPT o T5) entrenados sobre corpus masivos, capaces de generar texto, extraer conocimiento implícito y realizar razonamiento contextualizado \cite{nguyen2024}.

\subsection{Prompt Engineering}
Diseño estratégico de instrucciones o ejemplos para guiar la salida de un LLM, crucial en tareas de extracción de habilidades o clasificación de ocupaciones \cite{nguyen2024}.

\subsection{Few-shot learning}
Habilidad de los LLMs para realizar tareas complejas con pocos ejemplos, lo cual resulta clave cuando se carece de datasets etiquetados masivamente en español \cite{nguyen2024}.

\subsection{Embeddings semánticos}
Representaciones numéricas de textos que capturan similitudes semánticas, permitiendo análisis cuantitativos y clustering. Ejemplos incluyen word2vec, BERT y E5 \cite{kavas2024}.

\subsection{Embeddings multilingües}
Vectores entrenados para representar texto en múltiples idiomas en un mismo espacio semántico. Son esenciales para manejar contenido mixto español-inglés en ofertas laborales \cite{kavas2025}.

\subsection{UMAP (Reducción de dimensionalidad)}
Técnica que transforma espacios de alta dimensionalidad en representaciones más simples, conservando la estructura semántica subyacente para facilitar análisis y visualización.

\subsection{Clustering (HDBSCAN)}
Algoritmo no supervisado que detecta grupos naturales de observaciones (como habilidades o perfiles laborales) según su similitud semántica, sin requerir número de clusters predefinido \cite{lukauskas2023}.

\subsection{Taxonomía de habilidades (ESCO, CIUO-08, O*NET)}
Sistemas jerárquicos y normalizados de clasificación de habilidades y ocupaciones, fundamentales para anclar el análisis a estándares internacionales y mejorar interoperabilidad de los resultados \cite{echeverria2022, campos2024}.

\subsection{FAISS (Facebook AI Similarity Search)}
Biblioteca de código abierto para búsqueda eficiente de similitud en espacios vectoriales de alta dimensionalidad. El sistema utiliza FAISS IndexFlatIP para búsqueda exacta de vecinos más cercanos con producto interno, logrando velocidades de 30,147 consultas por segundo, aproximadamente 25 veces más rápido que PostgreSQL con pgvector.

\subsection{Estrategia de tres capas (Three-layer matching)}
Metodología implementada para mapear habilidades extraídas contra la taxonomía ESCO:
\begin{itemize}
    \item Layer 1 - Exact Match: Búsqueda exacta mediante SQL ILIKE con confianza 1.0
    \item Layer 2 - Fuzzy Match: Similitud difusa con fuzzywuzzy, threshold 0.85, confianza 0.85-1.0
    \item Layer 3 - Semantic Match: Búsqueda semántica con FAISS, threshold 0.87, confianza 0.87-1.0 (actualmente deshabilitado debido a limitaciones del modelo E5 con vocabulario técnico)
\end{itemize}

\subsection{Skills emergentes}
Habilidades extraídas de ofertas laborales que no pueden ser mapeadas a la taxonomía ESCO existente. Representan el 87.4\% de las skills extraídas y constituyen una señal valiosa sobre tendencias emergentes del mercado tech latinoamericano, no un fallo del sistema.

\subsection{Natural Language Processing (NLP)}
Conjunto de técnicas de inteligencia artificial, combinando modelos de lingüística computacional, machine learning y aprendizaje profundo, para poder procesar lenguaje humano.

\subsection{Python}
Lenguaje de programación ampliamente utilizado en ciencia de datos y NLP, por su sintaxis sencilla y librerías especializadas como scikit-learn, spaCy, transformers y pandas.

\section{Apreciación Global}

El presente documento de Especificación de Requerimientos del Software (SRS) tiene como objetivo presentar de manera estructurada y detallada los aspectos fundamentales del sistema ``\proyectoTitulo''. La organización del documento se ha realizado con el propósito de facilitar su comprensión tanto para usuarios técnicos como no técnicos, brindando una visión progresiva desde el contexto general hasta los requerimientos específicos del sistema.

El contenido del documento se distribuye de la siguiente manera:

\begin{itemize}
    \item En la Sección 1, se expone la introducción general del proyecto, incluyendo su propósito, alcance, definiciones clave, referencias utilizadas y una apreciación global de su contenido.

    \item La Sección 2 describe de manera general los factores que afectan al producto, incluyendo su perspectiva, interfaces con otros sistemas y con el usuario, consideraciones de hardware y software, restricciones de memoria, operaciones del sistema y requerimientos de adaptación al entorno.

    \item La Sección 3 presentará los requerimientos funcionales y no funcionales del sistema, detallando cada una de las funcionalidades esperadas, así como las restricciones y condiciones necesarias para su correcto funcionamiento.

    \item En las Secciones 4 y 5, se incluirán descripciones de cómo se piensan manejar los requerimientos mencionados anteriormente, así como el proceso de verificación y validación.

    \item Finalmente, se anexarán diagramas, tablas de trazabilidad y otros elementos que complementen la especificación del sistema.
\end{itemize}

Este documento servirá como base para el diseño, desarrollo, validación y evaluación del sistema propuesto, asegurando que todos los actores involucrados compartan una visión clara y consensuada de los objetivos, alcances y funcionalidades del software a implementar.

% ============================================================================
