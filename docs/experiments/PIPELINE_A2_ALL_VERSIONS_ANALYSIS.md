# Pipeline A.2 - An√°lisis de Todas las Versiones

**Fecha:** 2025-11-10

---

## Resumen Ejecutivo

Se evaluaron **4 versiones** del enfoque N-gram matching contra el gold standard de 300 ofertas:

| Versi√≥n | F1 | Precision | Recall | Skills/Job | FP/TP Ratio |
|---------|-----|-----------|--------|------------|-------------|
| **A2.2 (Tech only)** | **9.73%** | **10.61%** | **8.99%** | **95.28** | **8.43x** |
| A2.3 (Sin gen√©ricos) | 6.73% | 5.45% | 8.78% | 111.17 | 17.35x |
| A2.0 (Original) | 6.68% | 5.39% | 8.78% | 124.57 | 17.57x |
| A2.1 (Largos+Freq) | 1.40% | 2.24% | 1.02% | 10.99 | 43.58x |

**Mejor resultado:** A2.2 (Tech only) con F1 9.73%

**Comparaci√≥n con otros pipelines:**
- Pipeline A (Regex): F1 79.15% ‚Üí **8.1x mejor**
- Pipeline B (LLM): F1 84.26% ‚Üí **8.7x mejor**

---

## An√°lisis por Versi√≥n

### A2.0 - Original (85,039 n-gramas)

**Configuraci√≥n:**
- Todas las skills de ESCO (14,215)
- N-gramas de 1-4 tokens
- Sin filtros

**Resultados:**
```
F1:          6.68%
Precision:   5.39%
Recall:      8.78%
Skills/job:  124.57
TP:          164
FP:          2,881 (17.57x m√°s que TP)
FN:          1,704
F1=0:        24/300 ofertas (8.0%)
```

**Diagn√≥stico:**
- **Problema principal:** Explosi√≥n de falsos positivos (2,881 FP vs 164 TP)
- **Causa:** 99.19% de n-gramas vienen de skills gen√©ricas ("gestionar", "realizar", "supervisar")
- **Ejemplo:** "experiencia con Python" matchea contra 500+ skills irrelevantes

---

### A2.1 - Largos + Baja Frecuencia (55,589 n-gramas)

**Configuraci√≥n:**
- N-gramas ‚â• 3 tokens
- Frecuencia ‚â§ 10 skills por n-grama
- Elimina 29,450 n-gramas gen√©ricos (34.6%)

**Resultados:**
```
F1:          1.40% ‚ùå PEOR
Precision:   2.24%
Recall:      1.02% ‚ùå Colapso total
Skills/job:  10.99
TP:          19 (vs 164 en A2.0)
FP:          828
FN:          1,849
F1=0:        260/300 ofertas (86.7%) ‚ùå
```

**Diagn√≥stico:**
- **Filtro demasiado agresivo:** Elimin√≥ n-gramas √∫tiles
- **Recall colaps√≥:** De 8.78% ‚Üí 1.02%
- **86.7% de ofertas con F1=0:** El sistema casi no detecta nada

**¬øPor qu√© fall√≥?**

Muchas tech skills tienen n-gramas cortos:
- "Python" (1 token) ‚ùå Eliminado
- "SQL" (1 token) ‚ùå Eliminado
- "Machine Learning" (2 tokens) ‚ùå Eliminado
- "Apache Spark" (2 tokens) ‚ùå Eliminado

Solo sobreviven n-gramas largos y raros, que aparecen poco en ofertas reales.

---

### A2.2 - Solo Tech Skills (24,134 n-gramas) ‚úÖ MEJOR

**Configuraci√≥n:**
- 4,410 skills t√©cnicas:
  - 276 tech puras (onet_hot_tech, tier0_critical, etc.)
  - 3,219 knowledge skills
  - 915 gen√©ricas con keywords tech
- N-gramas ‚â• 3 caracteres

**Resultados:**
```
F1:          9.73% ‚úÖ MEJOR
Precision:   10.61% ‚úÖ 2x mejor que A2.0
Recall:      8.99% ‚âà Similar a A2.0
Skills/job:  95.28
TP:          168 (+ 4 vs A2.0)
FP:          1,416 (vs 2,881 en A2.0) ‚úÖ 50% menos FP
FN:          1,700
F1=0:        20/300 ofertas (6.7%)
Ratio FP/TP: 8.43x (vs 17.57x en A2.0) ‚úÖ Mejor
```

**¬øPor qu√© funciona mejor?**

1. **Elimina el ruido principal:**
   - Sin "gestionar tareas en relaci√≥n con los m√∫sicos"
   - Sin "supervisar procedimientos de instalaciones penitenciarias"
   - Sin "emplear pr√°cticas no opresivas"

2. **Mantiene cobertura tech:**
   - Python, Java, SQL, Docker, Kubernetes
   - Machine Learning, Deep Learning, Data Science
   - AWS, Azure, Google Cloud
   - React, Angular, Vue.js

3. **Mejor ratio se√±al/ruido:**
   - FP reducidos 50% (2,881 ‚Üí 1,416)
   - TP se mantienen (164 ‚Üí 168)

**Pero sigue siendo bajo (9.73%):**
- Ratio FP/TP: 8.43x (8 falsos positivos por cada verdadero)
- Skills/job: 95.28 (vs ~20 en gold standard)
- Precision 10.61% significa 89% de ruido

---

### A2.3 - Sin N-gramas Gen√©ricos (84,792 n-gramas)

**Configuraci√≥n:**
- Todas las skills de ESCO
- Eliminar n-gramas que aparecen en >50 skills
- Elimina solo 247 n-gramas (0.3%)

**Resultados:**
```
F1:          6.73%
Precision:   5.45%
Recall:      8.78%
Skills/job:  111.17
TP:          164
FP:          2,845 (17.35x)
FN:          1,704
F1=0:        24/300 ofertas (8.0%)
```

**Diagn√≥stico:**
- **Filtro insuficiente:** Solo elimina 247 de 85,039 n-gramas (0.3%)
- **Threshold de 50 es demasiado alto:** N-gramas como "gestionar" aparecen en 500 skills pero siguen pasando el filtro
- **Resultados casi id√©nticos a A2.0:** El filtro pr√°cticamente no tuvo efecto

**¬øPor qu√© no funcion√≥?**

El problema NO es n-gramas que aparecen en >50 skills, sino n-gramas que:
- Son palabras comunes del espa√±ol ("con", "para", "los")
- Aparecen en frases largas contextuales
- No son espec√≠ficos de un dominio

---

## Lecciones Aprendidas

### 1. Filtrar por frecuencia no es suficiente

**A2.3** elimin√≥ solo 0.3% de n-gramas (threshold = 50).
**A2.1** elimin√≥ 34.6% pero destruy√≥ el recall.

**Problema fundamental:** La frecuencia NO captura especificidad sem√°ntica.

- "Python" aparece en 3 skills ‚Üí Espec√≠fico ‚úÖ
- "gestionar" aparece en 500 skills ‚Üí Gen√©rico ‚ùå
- "aplicar conocimientos de" aparece en 200 skills ‚Üí Gen√©rico ‚ùå

Pero tambi√©n:
- "bases de datos" aparece en 50 skills ‚Üí ¬øEspec√≠fico o gen√©rico? ü§î

### 2. El mejor enfoque: Curaci√≥n de taxonom√≠a

**A2.2** funcion√≥ mejor porque **manualmente seleccionamos** skills t√©cnicas mediante:
- `skill_type IN ('onet_hot_tech', ...)`
- Keywords t√©cnicas (`software`, `programaci√≥n`, `datos`)

Esto es **curaci√≥n**, no autom√°tico.

### 3. Incluso la mejor versi√≥n (9.73%) es inaceptable

**Comparaci√≥n:**

| Pipeline | Approach | F1 | FP/TP Ratio |
|----------|----------|-----|-------------|
| A (Regex) | 548 patrones curados | 79.15% | ~0.2x |
| **A2.2 (N-grams)** | 24,134 n-gramas auto | **9.73%** | **8.43x** |
| B (LLM) | Comprensi√≥n sem√°ntica | 84.26% | ~0.1x |

**Conclusi√≥n:** Curaci√≥n manual de 548 patrones > Generaci√≥n autom√°tica de 24,134 n-gramas

### 4. El problema fundamental: Falta de contexto

N-gram matching NO puede resolver:

**Ejemplo 1: Ambig√ºedad l√©xica**
```
Texto: "Buscamos conductor para proyecto de integraci√≥n"
N-gram: "conductor"
Matches:
  ‚ùå "conductor el√©ctrico" (electricidad)
  ‚ùå "conductor de autob√∫s" (transporte)
  ‚ùå "conductor de orquesta" (m√∫sica)
  ‚úÖ ¬øNinguno es correcto? (se refiere a l√≠der de proyecto)
```

**Ejemplo 2: Colocaciones inv√°lidas**
```
Texto: "experiencia gestionando equipos"
N-gram: "gestionar"
Matches:
  ‚ùå "gestionar tareas en relaci√≥n con los m√∫sicos"
  ‚ùå "gestionar procedimientos penitenciarios"
  ‚ùå "gestionar programas nutricionales"
  ‚ùå (Ninguno captura "gestionar equipos t√©cnicos")
```

**Ejemplo 3: Skills compuestas**
```
Texto: "Python para Machine Learning"
N-grams extra√≠dos:
  ‚úÖ "Python" ‚Üí Correcto
  ‚úÖ "Machine Learning" ‚Üí Correcto
  ‚ùå "para" ‚Üí 1,060 skills irrelevantes
  ‚ùå "learning" ‚Üí 800 skills irrelevantes
```

---

## ¬øPor qu√© Pipeline A (Regex) s√≠ funciona?

Pipeline A tiene F1 79.15% con solo 548 patrones. ¬øPor qu√©?

### 1. Patrones espec√≠ficos con boundaries

```python
# Regex (Pipeline A)
r'\bPython\b'  # Solo matchea "Python" como palabra completa

# N-gram (Pipeline A2)
"python"  # Matchea en "python", "pythonista", "monty python"
```

### 2. Patrones contextuales

```python
# Regex captura contexto
r'experiencia en (\w+)'  # Extrae skills despu√©s de "experiencia en"
r'conocimientos de (\w+)'

# N-gram NO captura contexto
"experiencia" ‚Üí 500 skills
"experiencia en" ‚Üí 300 skills (sigue siendo ruido)
```

### 3. Categorizaci√≥n manual

```python
# Regex tiene categor√≠as curadas
PROGRAMMING_LANGUAGES = ['Python', 'Java', 'JavaScript', ...]
FRAMEWORKS = ['React', 'Angular', 'Django', ...]
DATABASES = ['MySQL', 'PostgreSQL', 'MongoDB', ...]

# N-gram mezcla todo
"Python (programaci√≥n)" + "Python (zoolog√≠a)" + "script Python" + ...
```

### 4. Exclusiones expl√≠citas

```python
# Regex puede excluir falsos positivos
r'\bPython\b(?! (serpiente|v√≠bora))'  # Excluye contexto zool√≥gico

# N-gram NO puede excluir
```

---

## Comparaci√≥n Final: Todas las Versiones

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  F1 Score Comparison                           ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                ‚îÇ
‚îÇ Pipeline B (LLM)      ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 84.26% ‚îÇ
‚îÇ Pipeline A (Regex)    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  79.15% ‚îÇ
‚îÇ                                                                ‚îÇ
‚îÇ A2.2 (Tech only)      ‚ñà‚ñà‚ñà                              9.73%  ‚îÇ
‚îÇ A2.3 (Sin gen√©ricos)  ‚ñà‚ñà                               6.73%  ‚îÇ
‚îÇ A2.0 (Original)       ‚ñà‚ñà                               6.68%  ‚îÇ
‚îÇ A2.1 (Largos+Freq)    ‚ñå                                1.40%  ‚îÇ
‚îÇ                                                                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

```

**Skills extra√≠das por oferta:**

| Pipeline | Skills/Job | Comentario |
|----------|------------|------------|
| Gold Standard | ~20 | Anotaci√≥n humana |
| Pipeline A (Regex) | 23.4 | Muy cercano ‚úÖ |
| Pipeline B (LLM) | 31.2 | Sobre-extracci√≥n leve |
| **A2.2 (Tech only)** | **95.28** | **5x m√°s de lo esperado** ‚ùå |
| A2.0 (Original) | 124.57 | 6x m√°s |
| A2.1 (Largos+Freq) | 10.99 | Mitad de lo esperado ‚ùå |

---

## Conclusiones

### ‚úÖ √âxitos del experimento

1. **Demostr√≥ emp√≠ricamente** que N-gram matching exhaustivo NO funciona
2. **Identific√≥** que A2.2 (curar taxonom√≠a) es crucial
3. **Mejor√≥** de 6.68% ‚Üí 9.73% mediante filtrado inteligente
4. **Document√≥** 4 enfoques diferentes y sus trade-offs

### ‚ùå Limitaciones insuperables

1. **F1 9.73% es inaceptable** para producci√≥n (vs 79.15% en Regex)
2. **8.43x m√°s falsos positivos** que verdaderos positivos
3. **95 skills/oferta** vs ~20 esperadas (inflaci√≥n 5x)
4. **Falta de contexto sem√°ntico** es un problema fundamental

### üéØ Valor para la tesis

Este experimento **fortalece tu investigaci√≥n** al:

1. Mostrar que exploraste **enfoques alternativos sistem√°ticamente**
2. Documentar **por qu√© NO funcionan** (tan valioso como mostrar qu√© s√≠ funciona)
3. Justificar **emp√≠ricamente** la elecci√≥n de Pipeline A y B
4. Demostrar **rigor metodol√≥gico** (4 variantes, evaluaci√≥n rigurosa)

### üìù Narrativa sugerida para la tesis

> "Se explor√≥ exhaustivamente el enfoque de N-gram matching contra la taxonom√≠a ESCO (14,215 skills), evaluando 4 variantes:
>
> - **A2.0 Original:** 85,039 n-gramas ‚Üí F1 6.68%
> - **A2.1 Largos+Freq:** Filtrado por longitud ‚Üí F1 1.40% (colapso de recall)
> - **A2.2 Tech only:** Curaci√≥n de taxonom√≠a ‚Üí F1 9.73% ‚úÖ (mejor resultado)
> - **A2.3 Sin gen√©ricos:** Threshold de frecuencia ‚Üí F1 6.73%
>
> Incluso la mejor variante (A2.2, F1 9.73%) es 8.1x peor que Pipeline A (Regex, F1 79.15%), con un ratio de 8.43 falsos positivos por cada verdadero positivo.
>
> **Hallazgo clave:** Las taxonom√≠as oficiales (ESCO), dise√±adas para clasificaci√≥n sem√°ntica, no son adecuadas para extracci√≥n lexicogr√°fica directa. La descomposici√≥n en n-gramas genera ruido l√©xico que no puede ser eliminado sin comprensi√≥n contextual. Este resultado valida la necesidad de curaci√≥n manual (Pipeline A) o comprensi√≥n sem√°ntica (Pipeline B) para extracci√≥n efectiva de skills t√©cnicas."

---

## Recomendaci√≥n Final

**NO usar ninguna versi√≥n de Pipeline A.2 en producci√≥n.**

**Continuar con:**
- ‚úÖ Pipeline A (Regex): F1 79.15%, interpretable, robusto
- ‚úÖ Pipeline B (LLM): F1 84.26%, estado del arte

**Pipeline A.2 cumpli√≥ su prop√≥sito:** Demostrar emp√≠ricamente las limitaciones del matching lexicogr√°fico exhaustivo.
