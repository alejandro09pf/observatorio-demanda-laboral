\chapter{Vista General del Proyecto}

\section{Visión del Producto}

El presente proyecto busca desarrollar un sistema semiautomatizado, ejecutable de forma periódica y local, que permita procesar y segmentar la demanda de habilidades tecnológicas en Colombia, México y Argentina mediante un pipeline de scraping, procesamiento semántico y visualización macro. El sistema permitirá generar insumos estructurados para el posterior análisis de tendencias laborales en el sector tecnológico latinoamericano, fortaleciendo la toma de decisiones por parte de instituciones educativas, investigadores y organismos interesados en cerrar brechas entre la formación y el mercado laboral.

Se espera que, una vez completado, el sistema siente las bases para futuras ampliaciones en cobertura territorial, frecuencia de actualización, refinamiento técnico y despliegue institucional, permitiendo construir un observatorio laboral replicable, contextualizado al español latinoamericano y alineado a estándares internacionales como ESCO o CIUO.

\section{Propósito, Alcance y Objetivos}

\subsection{Propósito}

Este proyecto se realiza con el fin de sentar las bases técnicas y metodológicas para un observatorio de demanda laboral tecnológica en Latinoamérica, integrando en un solo sistema fases de extracción, procesamiento y visualización de habilidades demandadas en vacantes reales en línea, con especial enfoque en el idioma español y el contexto regional.

\subsection{Alcance}

El proyecto contempla la implementación de un pipeline local compuesto por siete etapas secuenciales. Inicia con scraping de ocho portales de empleo en Colombia, México y Argentina, seguido de limpieza y normalización de datos. Posteriormente ejecuta extracción de habilidades mediante dos pipelines paralelos: Pipeline A basado en NER y expresiones regulares, y Pipeline B utilizando modelos de lenguaje grandes para enriquecimiento semántico. Las etapas finales incluyen representación vectorial con embeddings multilingües, clustering con UMAP y HDBSCAN, y generación de visualizaciones macro estáticas junto con análisis temporal.

Quedan fuera del alcance el desarrollo de dashboards interactivos en tiempo real, la construcción de portales web públicos, la automatización continua mediante orquestadores empresariales, y la integración con bases de datos externas o APIs privadas de portales de empleo.

\subsection{Objetivo general}

Desarrollar un sistema que permita procesar y segmentar la demanda de habilidades tecnológicas en Colombia, México y Argentina, mediante técnicas de procesamiento de lenguaje natural.

\subsection{Objetivos Específicos}

El proyecto contempla cuatro objetivos específicos que estructuran su desarrollo. El primero consiste en construir un estado del arte exhaustivo que permita comparar trabajos existentes en observatorios laborales automatizados y técnicas de procesamiento de lenguaje natural aplicadas al español, estableciendo así el marco conceptual y metodológico del sistema. El segundo objetivo busca diseñar una arquitectura modular, escalable y reutilizable para el observatorio, fundamentada en las mejores prácticas identificadas durante la revisión del estado del arte y adaptada a las particularidades del contexto latinoamericano.

El tercer objetivo se enfoca en implementar e integrar técnicas de inteligencia artificial para la identificación, normalización y agrupación semántica de habilidades tecnológicas en ofertas laborales en español, combinando métodos tradicionales basados en reglas con modelos de lenguaje modernos. Finalmente, el cuarto objetivo establece la necesidad de validar el desempeño y la robustez tanto de la arquitectura propuesta como de los modelos implementados, mediante métricas cuantitativas de precisión y recall, así como estudios empíricos sobre conjuntos de datos anotados manualmente.

\section{Supuestos y Restricciones}

\subsection{Supuestos}

El proyecto opera bajo cinco supuestos fundamentales que condicionan su viabilidad técnica y operativa. Se asume que será posible mantener acceso continuo a los portales de empleo seleccionados o sus APIs públicas para la extracción sistemática de vacantes durante todo el período de ejecución. Adicionalmente, se presupone la existencia de un corpus suficientemente amplio y variado de ofertas laborales publicadas en español que permita entrenar y validar los modelos de extracción con representatividad estadística adecuada.

Desde la perspectiva de infraestructura, se asume que el equipo contará con recursos computacionales locales adecuados para ejecutar las tareas técnicas del pipeline, incluyendo procesamiento de lenguaje natural, generación de embeddings y clustering de habilidades. En términos organizacionales, se supone que el equipo mantendrá coordinación fluida y comunicación efectiva durante las semanas de ejecución del proyecto. Finalmente, se presume que los modelos de lenguaje y bibliotecas de NLP seleccionados tendrán funcionamiento adecuado para el procesamiento de texto en español, particularmente considerando las variantes dialectales de Colombia, México y Argentina.

\subsection{Restricciones}

El proyecto enfrenta tres restricciones principales que delimitan su alcance y enfoque metodológico. La primera corresponde a la existencia de carga académica paralela por parte de los integrantes del equipo, quienes deben balancear el desarrollo del observatorio con otras responsabilidades curriculares del programa de Ingeniería de Sistemas, limitando así las horas semanales disponibles para dedicación exclusiva al proyecto.

La segunda restricción corresponde a la capacidad limitada de procesamiento computacional local, operando sin acceso a GPUs de alto rendimiento ni infraestructura de servidores externos, lo cual condiciona la selección de modelos de lenguaje hacia alternativas de tamaño intermedio ejecutables en hardware consumer con cuantización. La tercera restricción refleja el tiempo acotado disponible para experimentación iterativa en componentes que requieren ajuste manual, como el refinamiento de prompts para LLMs, la optimización de parámetros de clustering, y el diseño de visualizaciones interpretables, priorizando implementaciones funcionales sobre exploraciones exhaustivas de hiperparámetros.

\section{Entregables}

\begin{table}[H]
\centering
\begin{tabular}{|p{4cm}|p{4.5cm}|p{3cm}|p{2.5cm}|}
\hline
\textbf{Entregable} & \textbf{Descripción} & \textbf{Destinatario} & \textbf{Fecha estimada} \\
\hline
Repositorio funcional del sistema & Código completo de scraping, NER, LLMs, clustering y visualización & Docentes evaluadores & Semana 14 \\
\hline
Dataset limpio de vacantes y habilidades & Base de datos estructurada con datos procesados & Equipo y docentes & Semana 13 \\
\hline
Diccionario de habilidades y embeddings & Archivo con habilidades extraídas, enriquecidas y vectorizadas & Equipo técnico & Semana 10 \\
\hline
Visualizaciones macro & Gráficos estáticos de resultados para validación cualitativa & Asesor y evaluadores & Semana 12 \\
\hline
Documento explicativo del sistema & Guía metodológica, arquitectura y funcionamiento & Universidad / Archivo final & Semana 15 \\
\hline
Pruebas funcionales y logs & Evidencia de validación de módulos y resultados intermedios & Asesor y docentes & Semana 14 \\
\hline
\end{tabular}
\caption{Entregables del Proyecto}
\end{table}

\section{Resumen de Calendarización y Presupuesto}

\begin{table}[H]
\centering
\begin{tabular}{|l|l|c|}
\hline
\textbf{Fase} & \textbf{Actividad} & \textbf{Semanas} \\
\hline
F1 & Diseño y arquitectura del sistema & 1--2 \\
\hline
F2 & Scraping y carga a base de datos & 3--5 \\
\hline
F3 & Extracción de habilidades (NER + regex) & 6--7 \\
\hline
F4 & Enriquecimiento con LLMs & 8--9 \\
\hline
F5 & Embeddings + clustering & 10--11 \\
\hline
F6 & Visualización macro y evaluación & 12 \\
\hline
F7 & Pruebas, documentación y entrega final & 13--16 \\
\hline
\end{tabular}
\caption{Fases del Proyecto}
\end{table}

\begin{table}[H]
\centering
\begin{tabular}{|l|l|l|}
\hline
\textbf{Recurso} & \textbf{Descripción} & \textbf{Costo} \\
\hline
Infraestructura local & Uso de computadoras personales & Sin costo adicional \\
\hline
Modelos preentrenados & HuggingFace, spaCy, BETO, etc. & Gratuito (open source) \\
\hline
API de LLMs & GPT-3.5 para pruebas (en caso de acceso) & Versión gratuita / académica \\
\hline
Licencias y software & VSCode, GitHub, Dash, PostgreSQL & Gratuito \\
\hline
Herramientas de documentación & Google Docs, Overleaf, GitHub Wiki & Gratuito \\
\hline
\end{tabular}
\caption{Ítems Consolidados}
\end{table}

\section{Evolución del Plan}

El plan seguirá una lógica iterativa inspirada en CRISP-DM y Scrum no estricto. Cualquier cambio al plan será discutido en reuniones semanales y validado por consenso. Las actualizaciones serán registradas en Google Docs y GitHub, y se comunicarán al equipo con antelación. Las decisiones sobre cambios mayores (como rediseño de etapas o reemplazo de técnicas) deberán estar documentadas en el acta de revisión de fase correspondiente.
