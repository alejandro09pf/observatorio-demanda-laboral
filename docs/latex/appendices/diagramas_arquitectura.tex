\section*{APÉNDICE D: INFORMACIÓN ADICIONAL SOBRE ARQUITECTURA Y METODOLOGÍA}
\addcontentsline{toc}{section}{Apéndice D: Información Adicional sobre Arquitectura y Metodología}

Este apéndice proporciona información complementaria sobre los diagramas de arquitectura y metodología presentados en los capítulos 4 y 5 del documento principal. Se detallan las decisiones de diseño, comparaciones arquitectónicas, y el flujo de transformación de datos a través del pipeline.

\subsection*{D.1. Detalles del Flujo Metodológico}

El diagrama de flujo metodológico presentado en el Capítulo 4 (Figura \ref{fig:flujo-metodologico}) integra las seis fases de CRISP-DM con las siete etapas del pipeline de software. Los ciclos iterativos entre las fases de Modelado y Evaluación permitieron mejora incremental del sistema mediante:

\begin{itemize}
    \item \textbf{Refinamiento de parámetros NER}: Ajuste de umbrales de confianza, expansión del EntityRuler con patrones ESCO, y calibración de filtros de stopwords técnicas.
    \item \textbf{Optimización de patrones regex}: Incremento de 47 a 548 patrones organizados en 18 categorías técnicas, incorporando variantes ortográficas y versiones numeradas.
    \item \textbf{Evolución de prompts LLM}: Iteración de diseño de prompts desde versión inicial de 50 líneas hasta versión final de 170 líneas con ejemplos contextuales, manejo de Spanglish, y esquema JSON validado.
    \item \textbf{Calibración de clustering}: Experimentación con 70+ configuraciones de HDBSCAN para determinar \texttt{min\_cluster\_size=12} y \texttt{min\_samples=3} óptimos.
\end{itemize}

\subsection*{D.2. Detalles del Pipeline de 7 Etapas}

El diagrama de arquitectura modular presentado en el Capítulo 5 (Figura \ref{fig:arquitectura-completa}) muestra el pipeline secuencial de 7 etapas. Información adicional sobre tecnologías específicas por módulo:

\begin{itemize}
    \item \textbf{Scraping}: Framework Scrapy 2.11 con Selenium 4.15 para contenido dinámico, delays adaptativos (2-5s), rotación de user-agents, y backoff exponencial.
    \item \textbf{Extraction}: spaCy \texttt{es\_core\_news\_lg} v3.7 con EntityRuler personalizado, 548 patrones regex en 18 categorías, latencia 50-80ms por documento.
    \item \textbf{LLM Processing}: Gemma 3 4B con cuantización Q4 (4-6 GB VRAM), temperatura 0.3, max\_tokens 3072, latencia 18s (P50).
    \item \textbf{ESCO Matching}: Taxonomía extendida 14,215 skills (13,939 ESCO v1.1.0 + 152 O*NET + 124 manuales), matching exact + fuzzy $\geq$0.85.
    \item \textbf{Embedding}: Modelo \texttt{intfloat/multilingual-e5-base} (768D, 278M parámetros), batch\_size=32, latencia $<$100ms/batch.
    \item \textbf{UMAP}: Parámetros \texttt{n\_neighbors=15}, \texttt{min\_dist=0.1}, \texttt{metric='cosine'}, reducción 768D $\rightarrow$ 2-3D.
    \item \textbf{HDBSCAN}: Parámetros \texttt{min\_cluster\_size=12}, \texttt{min\_samples=3}, \texttt{cluster\_selection\_method='eom'}.
\end{itemize}

\subsection*{D.3. Flujo de Transformación de Datos}

El flujo de datos atraviesa las siguientes transformaciones principales desde la recolección inicial hasta la generación de visualizaciones finales, con estructuras de datos intermedias persistidas en PostgreSQL:

\begin{itemize}
    \item \textbf{raw\_jobs $\to$ cleaned\_jobs}: Normalización de encoding UTF-8, eliminación de HTML residual, detección de idioma (español/inglés/Spanglish), deduplicación SHA-256.
    \item \textbf{cleaned\_jobs $\to$ extracted\_skills}: Aplicación de Pipeline A (NER+Regex) con extracción de 27.6 skills promedio por oferta, 87.4\% emergent skills sin match ESCO.
    \item \textbf{cleaned\_jobs $\to$ enhanced\_skills}: Aplicación de Pipeline B (LLM) con prompt de 170 líneas, detección de hard skills (78.7\%) y soft skills (21.3\%).
    \item \textbf{extracted/enhanced\_skills $\to$ matched\_skills}: Normalización contra ESCO mediante 2 capas (exact + fuzzy), match rate 12.6\% baseline, 25\% con matcher mejorado.
    \item \textbf{matched\_skills $\to$ skill\_embeddings}: Vectorización con E5 Multilingual (768D), normalización L2, indexación FAISS para búsqueda rápida.
    \item \textbf{skill\_embeddings $\to$ umap\_projections}: Reducción dimensional con parámetros n\_neighbors=15, min\_dist=0.1, metric='cosine'.
    \item \textbf{umap\_projections $\to$ clusters}: Clustering HDBSCAN con min\_cluster\_size=12, min\_samples=3, identificación de 50 clusters principales.
\end{itemize}

\subsection*{D.4. Comparación de Estilos Arquitectónicos}

Durante la fase de diseño se evaluaron tres estilos arquitectónicos para el observatorio: microservicios, arquitectura orientada a eventos, y arquitectura de pipeline lineal. La Tabla \ref{tab:arch-comparison-anexo} presenta la comparación según criterios relevantes para el contexto académico y operativo del proyecto.

\begin{table}[H]
\centering
\caption{Comparación de Estilos Arquitectónicos Evaluados}
\label{tab:arch-comparison-anexo}
\begin{tabular}{|p{3cm}|p{3.5cm}|p{3.5cm}|p{3.5cm}|}
\hline
\textbf{Criterio} & \textbf{Microservicios} & \textbf{Event-Driven} & \textbf{Pipeline Lineal} \\
\hline
Complejidad & Alta & Media-alta & Baja \\
\hline
Escalabilidad horizontal & Excelente & Excelente & Limitada \\
\hline
Trazabilidad & Media & Media & Excelente \\
\hline
Debugging & Difícil & Medio & Fácil \\
\hline
Overhead operativo & Alto & Medio & Bajo \\
\hline
Time to market & Lento & Medio & Rápido \\
\hline
Requisitos infraestructura & K8s/Docker Swarm & Message broker & Servidor único \\
\hline
Tolerancia a fallos & Excelente & Buena & Media \\
\hline
Equipo requerido & 5+ devs & 3-4 devs & 2 devs \\
\hline
\end{tabular}
\end{table}

Se seleccionó arquitectura de pipeline lineal fundamentado en cuatro razones principales:

\begin{enumerate}
    \item \textbf{Simplicidad operativa}: Proyecto académico con equipo de 2 desarrolladores y recursos computacionales limitados (1 servidor, sin infraestructura Kubernetes/Docker Swarm).
    \item \textbf{Trazabilidad completa}: Flujo unidireccional de datos permite debugging determinístico y auditoría de transformaciones etapa por etapa.
    \item \textbf{Velocidad de desarrollo}: Implementación de microservicios requiere 3-4x más tiempo en configuración de comunicación inter-servicios, service discovery, y manejo de fallos distribuidos.
    \item \textbf{Naturaleza batch del dominio}: El análisis de demanda laboral no requiere procesamiento en tiempo real (latencias de horas/días son aceptables), eliminando ventajas principales de arquitecturas asíncronas.
\end{enumerate}

\subsection*{D.5. Limitaciones de la Arquitectura de Pipeline Lineal}

Es importante reconocer las limitaciones inherentes de la arquitectura seleccionada:

\begin{itemize}
    \item \textbf{Procesamiento secuencial sincrónico}: Impide aprovechamiento de paralelismo entre etapas, resultando en latencias acumulativas estimadas de 30-60 segundos por oferta para el pipeline completo cuando se incluye procesamiento con LLM.
    \item \textbf{Escalabilidad horizontal limitada}: La naturaleza monolítica del orquestador requeriría migración a arquitectura de microservicios si el volumen superara las 100,000 ofertas mensuales.
    \item \textbf{Ausencia de tolerancia a fallos distribuidos}: El fallo de una etapa detiene el pipeline completo, aunque esta limitación se mitiga mediante persistencia intermedia en PostgreSQL y capacidad de reinicio desde checkpoints.
\end{itemize}

Estas limitaciones fueron consideradas aceptables dado que:

\begin{itemize}
    \item El análisis de demanda laboral no requiere procesamiento en tiempo real.
    \item El volumen objetivo de 600,000 ofertas es procesable en 5-10 horas con el hardware disponible.
    \item La simplicidad operativa reduce significativamente el tiempo de desarrollo: 3-4 meses comparado con 9-12 meses que requeriría una arquitectura de microservicios.
    \item La arquitectura permite evolución futura mediante refactorización incremental de módulos críticos a servicios independientes si los requisitos de volumen o latencia lo justifican posteriormente.
\end{itemize}
