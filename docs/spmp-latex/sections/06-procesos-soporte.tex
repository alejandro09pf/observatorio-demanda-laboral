\chapter{Procesos de Soporte}

\section{Gestión de la Configuración}

La gestión de la configuración del proyecto tiene como propósito mantener la integridad, trazabilidad y control de versiones de todos los artefactos generados durante el desarrollo, incluyendo código fuente, datasets, documentación técnica, modelos entrenados, scripts de procesamiento y archivos de configuración. Dado el carácter académico del proyecto y su naturaleza modular, se adoptará un enfoque pragmático basado en Git, GitHub y herramientas colaborativas de documentación, sin pretender alcanzar niveles de formalidad propios de entornos empresariales regulados.

\subsection{Elementos de Configuración}

Los elementos que estarán bajo control de configuración incluyen:

\begin{table}[H]
\centering
\small
\begin{tabular}{|p{3.5cm}|p{5cm}|p{3cm}|p{2.5cm}|}
\hline
\textbf{Elemento de configuración} & \textbf{Descripción} & \textbf{Herramienta de gestión} & \textbf{Responsable} \\
\hline
Código fuente del sistema & Scripts de scraping, NER, LLMs, clustering y visualización en Python & GitHub & Nicolás \\
\hline
Configuraciones de entorno & Archivos .env, config.json, requirements.txt, docker-compose.yml & GitHub & Nicolás \\
\hline
Bases de datos y esquemas & Dump SQL de PostgreSQL con estructura de tablas y datos procesados & GitHub + Google Drive & Nicolás \\
\hline
Documentación técnica del proyecto & Documento SPMP, SRS, memoria técnica, manuales & Google Docs + Overleaf & Alejandro \\
\hline
Notebooks de análisis & Jupyter notebooks con pruebas exploratorias, validaciones y visualizaciones & GitHub & Nicolás \\
\hline
Datasets intermedios & Archivos CSV, JSON o pickle con datos procesados por fase & Google Drive & Nicolás \\
\hline
Modelos y embeddings & Archivos de modelos descargados o ajustados, vectores precomputados & Google Drive & Nicolás \\
\hline
Actas de reunión y seguimiento & Registros de reuniones semanales y decisiones de equipo & Google Docs & Alejandro \\
\hline
\end{tabular}
\caption{Elementos de Configuración del Proyecto}
\end{table}

\subsection{Proceso de Control de Versiones}

El control de versiones del código fuente y de los artefactos técnicos del proyecto se realizará mediante Git como sistema de control distribuido y GitHub como plataforma de hospedaje y colaboración remota, siguiendo cinco prácticas fundamentales de ingeniería de software que garantizan trazabilidad histórica, integración controlada y recuperabilidad ante errores.

La primera práctica establece rama principal denominada main como línea base estable del sistema, conteniendo únicamente código probado funcionalmente y validado técnicamente al cierre de cada fase metodológica del CRISP-DM. Los commits directos a esta rama están prohibidos, requiriendo obligatoriamente revisión previa mediante pull request aprobado por líder técnico Nicolás Camacho. La segunda práctica crea ramas de desarrollo dedicadas por fase metodológica siguiendo nomenclatura estandarizada dev-fase-X donde X identifica número de fase, permitiendo desarrollo paralelo aislado de funcionalidades correspondientes sin afectar estabilidad de main. Al completar validación técnica satisfactoria de fase, rama temporal se fusiona a main mediante pull request con revisión de código y resolución de conflictos de merge.

La tercera práctica exige commits descriptivos con mensajes claros estructurados que indiquen qué cambio técnico se realizó describiendo alcance específico de modificación, por qué razón se ejecutó justificando decisión arquitectónica o corrección de bug, y en qué fase del proyecto se efectuó para facilitar trazabilidad cronológica. El formato estandarizado sugerido sigue convención de prefijo por fase: [FASE-X] seguido de descripción concisa del cambio en modo imperativo presente. La cuarta práctica implementa versionado semántico para entregas formales de entregables mayores, etiquetando commits significativos con tags de versión siguiendo convención v0.1 para prototipos iniciales, v0.2 para iteraciones intermedias, hasta v1.0 para release académico final, facilitando identificación y recuperación de estados históricos específicos del sistema.

La quinta práctica establece sincronización diaria obligatoria donde los integrantes deben ejecutar git push de avances locales al menos una vez al día laboral al finalizar sesión de trabajo, garantizando que repositorio remoto GitHub refleje estado actual de desarrollo y minimizando riesgo de conflictos masivos de integración acumulados. Esta práctica facilita colaboración efectiva permitiendo revisión continua cruzada de código entre integrantes y backup automático diario de trabajo en progreso.

\subsection{Gestión de Cambios en la Configuración}

Cualquier cambio propuesto en la configuración técnica del sistema incluyendo modificación de estructura de esquema relacional de base de datos PostgreSQL, reemplazo o actualización de versión de bibliotecas clave del stack Python, o ajuste significativo de arquitectura de scrapers web que afecte modularidad o extensibilidad, deberá seguir procedimiento formal estructurado de cinco etapas secuenciales que garantizan análisis riguroso de impacto y trazabilidad completa de decisiones técnicas.

La primera etapa requiere que el integrante que identifica necesidad del cambio documente exhaustivamente razón técnica fundamentada que motiva modificación propuesta con evidencia empírica de problema actual o limitación detectada, impacto esperado sobre funcionalidad del sistema cuantificando mejora en métricas de desempeño o calidad esperadas, y alternativas técnicas evaluadas mediante análisis comparativo de trade-offs entre opciones consideradas.

La segunda etapa ejecuta discusión estructurada en reunión semanal del equipo donde se debate colaborativamente si el cambio propuesto es técnicamente necesario para cumplir objetivos funcionales o no funcionales del proyecto, viable de implementar dentro de restricciones de tiempo y recursos computacionales disponibles, y académicamente justificado alineándose con metodología CRISP-DM establecida y aportes esperados del trabajo de grado.

La tercera etapa implementa el cambio aprobado mediante desarrollo en rama específica de Git denominada feature/nombre-cambio aislada de main, ejecuta pruebas funcionales exhaustivas localmente en entorno de desarrollo de integrante responsable validando que modificación no introduce regresiones críticas en módulos dependientes, y documenta técnicamente el cambio en archivo README principal del repositorio o mediante comentarios explicativos inline en código fuente modificado describiendo justificación y procedimiento de uso.

La cuarta etapa abre pull request formal en GitHub para revisión técnica obligatoria por parte de Nicolás Camacho como líder técnico antes de autorizar fusión a rama principal main, incluyendo descripción detallada del cambio, screenshots o logs de pruebas ejecutadas exitosamente, y análisis de impacto en otros módulos del sistema para facilitar evaluación informada de revisor.

La quinta etapa final actualiza archivo de configuración correspondiente del sistema como config.json o variables de entorno en archivo .env con nuevos parámetros o versiones de dependencias, registra formalmente el cambio aprobado en acta semanal de reunión con justificación técnica resumida, y comunica modificación al equipo completo mediante mensaje en canal de comunicación del proyecto explicando qué cambió y cómo afecta workflow de desarrollo de otros integrantes.

\begin{figure}[H]
\centering
\includegraphics[width=0.95\textwidth]{figures/BPMNControldeCambios.png}
\caption{Proceso de Gestión de Cambios en la Configuración (BPMN)}
\label{fig:bpmn-cambios}
\end{figure}

\subsection{Backup y Recuperación}

Para garantizar disponibilidad continua de los artefactos del proyecto ante pérdidas accidentales por fallas de hardware, errores humanos de borrado o corrupción de archivos, se implementarán cuatro medidas complementarias de respaldo y recuperación que operan en diferentes niveles de granularidad temporal y tipo de contenido.

La primera medida establece GitHub como repositorio central de versionado distribuido donde todo el código fuente Python, scripts de análisis, documentación técnica en formato Markdown y LaTeX, y archivos de configuración del sistema se alojarán con historial completo de commits. Esta plataforma ofrece redundancia automática geográfica mediante replicación en múltiples datacenters, control de versiones granular permitiendo recuperar cualquier estado histórico del código mediante git checkout o revert, y mecanismo de recuperación ante errores mediante creación de branches de rollback o cherry-pick de commits específicos.

La segunda medida utiliza Google Drive compartido institucional como almacenamiento de archivos de gran tamaño que exceden límites prácticos de Git, incluyendo datasets intermedios en formato CSV o pickle superiores a 100 MB, modelos preentrenados descargados de HuggingFace con pesos completos, documentos de trabajo en edición activa mediante Google Docs con sincronización en tiempo real, y archivos binarios de visualizaciones en alta resolución. La carpeta compartida tiene acceso restringido exclusivamente al equipo de desarrollo mediante autenticación institucional, versionado automático de Google Drive que retiene versiones de archivos modificados durante 30 días, y cuota de almacenamiento asignada de 15 GB por integrante.

La tercera medida exige backups semanales locales obligatorios donde cada integrante del equipo mantiene copia local completa del repositorio GitHub actualizada, sincronizada semanalmente mediante git pull origin main para incorporar cambios remotos, almacenada en disco duro local con respaldo adicional en disco externo o partición secundaria, y verificada mensualmente mediante ejecución de tests de integridad que confirmen que repositorio local puede ejecutar pipeline completo sin dependencias externas.

La cuarta medida implementa exportaciones SQL periódicas automatizadas de base de datos PostgreSQL ejecutadas al finalizar cada una de las siete fases técnicas del proyecto, generando archivo dump completo mediante comando pg_dump con compresión gzip, nomenclatura estandarizada incluyendo fecha ISO 8601 y número de versión semántica para identificación unívoca, y almacenamiento redundante tanto en repositorio GitHub dentro de límites de tamaño como en Google Drive para dumps superiores a 50 MB, garantizando recuperabilidad completa de esquema relacional y datos de producción.

En caso de materialización de pérdida de datos por cualquier causa identificada, el procedimiento de recuperación seguirá protocolo escalonado según severidad. Para pérdida de código fuente o documentación técnica versionada, se recurrirá al historial completo de GitHub mediante git log para identificar último commit válido y git reset para restaurar estado funcional previo al error. Para pérdida de datasets o modelos grandes, se descargarán copias de respaldo desde Google Drive compartido verificando integridad mediante checksums MD5 si disponibles. Si un integrante pierde completamente su copia local de trabajo por falla catastrófica de hardware, podrá ejecutar recuperación completa mediante git clone del repositorio completo desde GitHub para obtener código fuente, descarga de carpeta compartida de Google Drive para recuperar datasets y modelos grandes, y restauración de dump SQL más reciente de PostgreSQL para reconstruir base de datos operativa, completando proceso de recuperación en tiempo estimado de 2 a 4 horas dependiendo de velocidad de conexión a internet.

\section{Aseguramiento de Calidad}

El aseguramiento de calidad tiene como objetivo garantizar que los entregables del proyecto cumplan con los estándares técnicos esperados, funcionen correctamente en distintos escenarios de uso, y estén adecuadamente documentados para facilitar su comprensión, validación y réplica por terceros. Dado el contexto académico, se priorizará la validación funcional, la coherencia metodológica y la transparencia técnica por encima de métricas formales de calidad de software empresarial.

\subsection{Estándares de Calidad Aplicados}

El desarrollo del observatorio seguirá cinco estándares complementarios de calidad técnica que garantizan legibilidad del código, mantenibilidad del sistema, reproducibilidad científica y coherencia con mejores prácticas de ingeniería de software académico y profesional.

El primer estándar adopta convenciones de estilo PEP 8 como guía oficial para todo el código Python del proyecto, incluyendo uso obligatorio de nombres de variables y funciones descriptivos en snake_case que comuniquen claramente propósito y contenido, separación lógica clara de funciones mediante líneas en blanco según nivel de cohesión funcional, indentación consistente de 4 espacios sin uso de tabuladores para garantizar visualización uniforme en diferentes editores, y límite sugerido de 100 caracteres por línea de código cuando sea posible sin comprometer legibilidad, aceptando excepciones justificadas para strings largos de prompts LLM o URLs completas en comentarios.

El segundo estándar exige modularidad y reutilización mediante diseño arquitectónico donde cada una de las siete fases del pipeline CRISP-DM será implementada como módulo Python independiente con responsabilidad única bien definida, entradas explícitamente tipadas mediante type hints de Python 3.10+ especificando tipos de datos esperados, salidas claramente documentadas retornando estructuras de datos consistentes como DataFrames de pandas o diccionarios con esquema predefinido, y acoplamiento mínimo entre módulos comunicándose exclusivamente mediante interfaces públicas sin dependencias circulares, facilitando depuración aislada de componentes individuales, testing unitario independiente por módulo y reutilización futura de componentes en proyectos relacionados.

El tercer estándar requiere documentación interna exhaustiva del código donde funciones con complejidad ciclomática superior a 5 o que implementen lógica de negocio no trivial deberán incluir docstrings explicativas detalladas en español siguiendo formato Google o NumPy, indicando propósito claro de la función describiendo qué problema resuelve y por qué existe, parámetros de entrada con tipos esperados y restricciones de valores válidos, salida esperada especificando tipo de dato retornado y significado semántico, excepciones que pueden lanzarse documentando condiciones que las activan, y ejemplo de uso mínimo mostrando llamada típica con valores reales y resultado esperado para facilitar comprensión rápida de API.

El cuarto estándar implementa manejo robusto de errores mediante estrategia defensiva que incluye validaciones básicas de entrada al inicio de funciones críticas verificando tipos de datos, rangos numéricos válidos y existencia de archivos requeridos antes de procesamiento, manejo explícito de excepciones mediante bloques try-except con captura específica de tipos de error esperados como FileNotFoundError, JSONDecodeError o ConnectionError en lugar de excepciones genéricas, mensajes de error claros y accionables que informen al usuario qué falló, por qué ocurrió el error y qué acción correctiva puede tomar, y logging estructurado de eventos críticos mediante biblioteca logging de Python con niveles apropiados DEBUG para trazas detalladas, INFO para hitos de progreso, WARNING para situaciones anómalas recuperables y ERROR para fallos críticos, facilitando diagnóstico post-mortem de problemas en producción.

El quinto estándar garantiza reproducibilidad técnica completa mediante documentación exhaustiva donde todos los procesos del pipeline estarán descritos con suficiente detalle granular en README técnico, notebooks Jupyter comentados y documento de metodología del trabajo de grado, permitiendo que investigador externo con conocimientos técnicos de nivel medio en Python, procesamiento de lenguaje natural y bases de datos relacionales pueda replicar sistema completo desde cero, obteniendo resultados estadísticamente equivalentes a los reportados considerando variabilidad estocástica inherente a modelos de lenguaje y algoritmos de clustering no deterministas, validado mediante prueba empírica de instalación ejecutada por persona externa al equipo de desarrollo en máquina limpia sin configuración previa.

\subsection{Actividades de Verificación y Validación}

Las actividades de verificación (¿construimos el sistema correctamente?) y validación (¿construimos el sistema correcto?) se llevarán a cabo de forma iterativa en cada fase del proyecto:

\begin{table}[H]
\centering
\small
\begin{tabular}{|p{3cm}|p{4.5cm}|p{4cm}|p{2.5cm}|}
\hline
\textbf{Fase} & \textbf{Actividad de verificación} & \textbf{Actividad de validación} & \textbf{Responsable} \\
\hline
Scraping & Revisar que las vacantes extraídas tengan estructura completa y datos válidos & Comparar muestra manual con resultados del scraper para verificar precisión & Nicolás \\
\hline
NER y regex & Ejecutar el script sobre un conjunto de prueba y verificar que extrae habilidades sin errores de sintaxis & Revisar manualmente 50 vacantes y evaluar si las habilidades extraídas son correctas y relevantes & Alejandro \\
\hline
LLMs & Probar distintos prompts y verificar que el formato de salida es consistente & Evaluar cualitativamente si las habilidades enriquecidas tienen sentido técnico y semántico & Nicolás \\
\hline
Embeddings y clustering & Verificar que las dimensiones de los vectores son correctas y que HDBSCAN no arroja errores & Inspeccionar visualmente los clusters generados y verificar que agrupan habilidades coherentes & Nicolás \\
\hline
Visualización & Comprobar que los gráficos se generan sin errores y se exportan correctamente & Revisar con el asesor si las visualizaciones comunican información relevante de forma clara & Alejandro \\
\hline
\end{tabular}
\caption{Actividades de Verificación y Validación por Fase}
\end{table}

\begin{figure}[H]
\centering
\includegraphics[width=0.95\textwidth]{figures/BPMNControlCalidad.png}
\caption{Proceso de Control de Calidad del Proyecto (BPMN)}
\label{fig:bpmn-calidad}
\end{figure}

\subsection{Revisión Técnica de Entregables}

Al finalizar cada una de las siete fases metodológicas del pipeline CRISP-DM, se ejecutará revisión técnica formal estructurada del entregable correspondiente siguiendo procedimiento de cinco etapas secuenciales que garantizan calidad funcional, coherencia arquitectónica y alineación con objetivos académicos del trabajo de grado.

La primera etapa consiste en presentación formal del entregable donde el integrante responsable de la fase expone módulo desarrollado al equipo completo durante reunión semanal de seguimiento con duración estimada de 30 a 45 minutos, explicando arquitectura e implementación técnica del código con énfasis en decisiones de diseño no triviales, decisiones clave tomadas durante desarrollo incluyendo alternativas evaluadas y criterios de selección aplicados, y resultados técnicos obtenidos mediante ejecución sobre datos reales con análisis de métricas de desempeño, calidad de outputs y tiempo de procesamiento observado.

La segunda etapa ejecuta revisión colaborativa de código donde los demás integrantes del equipo clonan rama de desarrollo del módulo en sus entornos locales, revisan exhaustivamente código fuente Python mediante lectura crítica de implementación buscando bugs potenciales, code smells o violaciones de estándares PEP 8, prueban módulo localmente ejecutando pipeline completo sobre muestra representativa de datos para verificar reproducibilidad de resultados reportados, y formulan preguntas técnicas fundamentadas sobre decisiones de implementación o identifican posibles mejoras de eficiencia, legibilidad o robustez ante casos extremos.

La tercera etapa redacta checklist de verificación formal con criterios mínimos de aceptación específicos al tipo de entregable, incluyendo preguntas técnicas binarias como si el código ejecuta sin errores críticos que detengan ejecución en condiciones normales de entrada, si los datos de salida generados tienen estructura esperada conforme a especificación de interfaz del módulo validada mediante inspección de schemas, si está adecuadamente documentado el proceso mediante docstrings de funciones principales y comentarios explicativos inline en secciones complejas, si manejo de errores cubre casos extremos identificados mediante análisis de riesgos, y si desempeño de ejecución es razonable completando procesamiento de corpus completo en tiempo compatible con cronograma del proyecto.

La cuarta etapa toma decisión formal de aceptación donde si el entregable cumple todos los criterios obligatorios del checklist se aprueba formalmente mediante consenso del equipo, se fusiona a rama principal main mediante pull request con squash de commits para mantener historial limpio, y se etiqueta con tag de versión semántica correspondiente a fase completada; alternativamente si el entregable no cumple criterios críticos se registra lista detallada de correcciones pendientes priorizadas por severidad en documento de issues de GitHub, se establece plazo concreto de 3 a 5 días para aplicar correcciones identificadas según complejidad de cambios requeridos, y se programa sesión de re-revisión para validar implementación de mejoras solicitadas.

La quinta etapa final involucra validación académica donde el asesor del proyecto Ing. Luis Gabriel Moreno Sandoval revisa el entregable técnico aprobado internamente durante reunión quincenal de seguimiento con duración de 1 hora, valida que implementación esté técnicamente alineada con objetivos específicos del trabajo de grado y metodología CRISP-DM establecida, verifica que resultados obtenidos sean académicamente defendibles mediante comparación con benchmarks de literatura o análisis de coherencia semántica cualitativa, y provee retroalimentación formal escrita en acta de reunión con aprobación explícita o solicitudes de refinamiento adicional antes de proceder a siguiente fase del proyecto.

\subsection{Métricas de Calidad}

La evaluación cuantitativa y cualitativa de calidad del sistema desarrollado se fundamentará en cinco métricas complementarias que cubren dimensiones de completitud funcional, exactitud de outputs, interpretabilidad de resultados, complejidad del código y legibilidad para terceros.

La primera métrica mide cobertura de requisitos funcionales calculada como porcentaje de requisitos funcionales prioritarios del sistema especificados en documento SRS que han sido completamente implementados en código Python funcional y validados mediante pruebas de aceptación, respecto al total de requisitos funcionales definidos inicialmente, estableciendo umbral mínimo de aceptación de 90 por ciento para requisitos críticos del pipeline y 70 por ciento para requisitos opcionales de mejoras futuras.

La segunda métrica cuantifica tasa de errores en validación manual determinada como proporción de habilidades técnicas extraídas por Pipeline A mediante NER y regex o enriquecidas semánticamente por Pipeline B mediante LLM que son incorrectas por no corresponder a habilidades técnicas reales, irrelevantes por ser demasiado genéricas o fuera de dominio tecnológico, o mal normalizadas a taxonomía ESCO sin correspondencia semántica adecuada, evaluada mediante inspección manual exhaustiva sobre muestra estadísticamente representativa de 100 registros seleccionados aleatoriamente del corpus completo, estableciendo umbral de calidad aceptable inferior a 15 por ciento de errores para Pipeline A y 10 por ciento para Pipeline B considerando su mayor sofisticación.

La tercera métrica evalúa coherencia semántica de clusters generados mediante análisis cualitativo experto de si los grupos de habilidades identificados por HDBSCAN tienen sentido técnico y semántico coherente agrupando tecnologías relacionadas por dominio de aplicación, stack tecnológico compartido o nivel de abstracción similar, mediante inspección visual de proyecciones UMAP bidimensionales con etiquetado de clústeres principales, revisión de listas de top 10 habilidades más frecuentes por cluster, y discusión estructurada con el asesor académico sobre interpretabilidad de taxonomía emergente identificada, documentando ejemplos de clusters exitosos y outliers problemáticos para refinamiento iterativo de hiperparámetros.

La cuarta métrica monitorea complejidad ciclomática moderada del código mediante análisis estático con herramientas como radon o flake8 verificando que funciones individuales del sistema mantengan complejidad ciclomática inferior a 10 para favorecer testabilidad y comprensión, evitando bloques de código excesivamente largos superiores a 100 líneas por función que indiquen falta de descomposición modular, o anidamiento excesivo de condicionales y loops superiores a 4 niveles de profundidad que dificulten seguimiento de flujo de control, estableciendo como objetivo que 80 por ciento de funciones tengan complejidad inferior a 5 indicando diseño simple y directo.

La quinta métrica evalúa legibilidad del código mediante análisis subjetivo de si el código fuente Python es comprensible y mantenible para desarrollador externo con experiencia intermedia en el lenguaje pero sin conocimiento previo del dominio específico del observatorio, verificada empíricamente mediante revisión cruzada entre integrantes del equipo donde cada desarrollador lee e interpreta código escrito por el otro sin consultar documentación externa, midiendo tiempo necesario para comprender propósito de módulo y localizar componente específico, y documentando sugerencias de mejora de nombres de variables, estructura de funciones o comentarios explicativos para incrementar claridad y reducir curva de aprendizaje de futuros mantenedores del sistema.

\section{Gestión de Riesgos}

La gestión de riesgos del proyecto tiene como objetivo identificar de forma anticipada las amenazas potenciales que puedan afectar el cronograma, la calidad técnica, los recursos disponibles o el cumplimiento de los objetivos, y definir estrategias de mitigación y contingencia para minimizar su impacto en caso de materializarse.

\subsection{Identificación de Riesgos}

A continuación, se presentan los principales riesgos identificados para el proyecto, clasificados por categoría:

\begin{table}[H]
\centering
\small
\begin{tabular}{|c|p{5cm}|c|c|p{4cm}|}
\hline
\textbf{ID} & \textbf{Descripción del riesgo} & \textbf{Prob.} & \textbf{Impacto} & \textbf{Categoría} \\
\hline
R01 & Cambios en la estructura HTML de portales de empleo que rompan el scraper & Media & Alto & Técnico \\
\hline
R02 & Bloqueo o limitación de acceso por parte de los portales web (anti-scraping) & Media & Alto & Técnico \\
\hline
R03 & Rendimiento insuficiente del modelo NER en español para el dominio laboral & Media & Medio & Técnico \\
\hline
R04 & Falta de datos suficientes o de calidad en portales de algunos países & Baja & Alto & Técnico \\
\hline
R05 & Complejidad técnica excesiva en implementación de clustering semántico & Media & Medio & Técnico \\
\hline
R06 & Sobrecarga académica de los integrantes afectando disponibilidad semanal & Alta & Medio & Organizacional \\
\hline
R07 & Retrasos acumulados que comprometan el cronograma general del proyecto & Media & Alto & Organizacional \\
\hline
R08 & Falta de coordinación o conflictos internos en el equipo & Baja & Medio & Organizacional \\
\hline
R09 & Fallas técnicas en equipos personales (hardware, conectividad, software) & Baja & Medio & Infraestructura \\
\hline
R10 & Pérdida de datos por falta de backups adecuados & Baja & Alto & Infraestructura \\
\hline
\end{tabular}
\caption{Identificación y Clasificación de Riesgos}
\end{table}

\begin{figure}[H]
\centering
\includegraphics[width=0.95\textwidth]{figures/BPMNIdentificaciondeRiesgos.png}
\caption{Proceso de Identificación y Gestión de Riesgos (BPMN)}
\label{fig:bpmn-riesgos}
\end{figure}

\subsection{Análisis de Riesgos}

Cada riesgo ha sido evaluado en términos de probabilidad de ocurrencia (Baja, Media, Alta) e impacto en el proyecto (Bajo, Medio, Alto), permitiendo priorizarlos según su nivel de criticidad.

El análisis cuantitativo de riesgos identifica cuatro amenazas de mayor criticidad que combinan probabilidad media-alta con impacto alto sobre el proyecto, clasificadas en dos categorías principales. La primera categoría corresponde a riesgos técnicos de scraping, específicamente R01 relacionado con cambios estructurales en HTML de portales de empleo que rompan funcionamiento de scrapers implementados requiriendo mantenimiento correctivo urgente, y R02 asociado a bloqueo o limitación de acceso mediante técnicas anti-scraping como CAPTCHAs, rate limiting o blacklisting de IP que restrinjan capacidad de recolección masiva de datos. Estos riesgos técnicos afectarían directamente disponibilidad del corpus de vacantes laborales requerido como insumo fundamental del pipeline completo, pudiendo paralizar fases posteriores de procesamiento NLP y análisis semántico hasta que se resuelva problema de adquisición de datos.

La segunda categoría engloba riesgos organizacionales de gestión de proyecto, específicamente R06 relacionado con sobrecarga académica de integrantes por compromisos paralelos en otras asignaturas del programa curricular de Ingeniería de Sistemas que reduce disponibilidad horaria semanal efectiva por debajo de estimación inicial de 8 a 12 horas por persona, y R07 asociado a retrasos acumulados en entrega de fases metodológicas que comprometan cumplimiento del cronograma general de 16 semanas establecido para completar trabajo de grado. Estos riesgos organizacionales podrían generar efecto cascada de retrasos progresivos donde demoras tempranas en fases críticas de path crítico se amplifican en etapas posteriores, forzando reducción de alcance funcional o solicitud de extensión formal de plazo académico ante dirección de programa.

Estos cuatro riesgos de criticidad alta recibirán especial atención prioritaria en definición de estrategias de mitigación preventiva detalladas, monitoreo continuo semanal mediante indicadores de alerta temprana específicos, y activación inmediata de planes de contingencia reactiva en caso de materialización confirmada durante ejecución del proyecto.

\subsection{Estrategias de Mitigación}

Para cada riesgo prioritario, se definen las siguientes estrategias de mitigación:

\begin{table}[H]
\centering
\small
\begin{tabular}{|c|p{5.5cm}|p{5.5cm}|}
\hline
\textbf{ID} & \textbf{Estrategia de mitigación (preventiva)} & \textbf{Plan de contingencia (reactiva)} \\
\hline
R01 & Diseñar scrapers modulares y flexibles. Revisar semanalmente la estructura de los portales durante la fase de scraping. & Si un portal cambia, ajustar el scraper en un plazo máximo de 3 días. Si no es viable, reemplazar por otro portal del mismo país. \\
\hline
R02 & Implementar delays aleatorios entre peticiones, rotar user agents, respetar robots.txt y usar Selenium/Playwright cuando sea necesario. & Si un portal bloquea el acceso, cambiar a scraping manual asistido o buscar datasets públicos alternativos (APIs, Kaggle). \\
\hline
R03 & Probar varios modelos NER en español (spaCy, BETO, modelos de HuggingFace) en etapa temprana. Validar con muestras pequeñas antes de procesar todo el corpus. & Si el rendimiento es bajo, complementar con expresiones regulares ad-hoc, diccionarios de habilidades predefinidos, o ajuste manual de resultados. \\
\hline
R04 & Validar acceso a portales y disponibilidad de vacantes antes de iniciar scraping masivo. Tener al menos 2 portales por país como respaldo. & Si un país tiene datos insuficientes, reducir su alcance o reemplazarlo por otro país latinoamericano con mayor disponibilidad. \\
\hline
R05 & Comenzar con técnicas simples (K-Means, DBSCAN) antes de pasar a HDBSCAN. Realizar pruebas con datasets sintéticos pequeños. & Si HDBSCAN no converge o genera clusters poco útiles, reducir dimensionalidad con PCA en lugar de UMAP, o aplicar clustering jerárquico tradicional. \\
\hline
R06 & Planificar cronograma considerando semanas de exámenes y entregas paralelas. Distribuir carga de trabajo de forma flexible. & Si un integrante tiene sobrecarga puntual, redistribuir tareas urgentes entre el resto del equipo temporalmente. \\
\hline
R07 & Hacer seguimiento semanal estricto del cronograma. Detectar retrasos tempranamente y aplicar correcciones inmediatas. & Si el retraso es mayor a 2 semanas, reducir el alcance de fases menos críticas o solicitar extensión formal del plazo final. \\
\hline
R09 & Mantener backups semanales en GitHub y Google Drive. Documentar configuraciones de entorno en README. & Si un equipo falla, el integrante afectado podrá clonar el repositorio completo en otro equipo y continuar trabajando con mínima pérdida de tiempo. \\
\hline
R10 & Implementar sistema de backups automáticos semanales en GitHub y Google Drive. Verificar integridad de backups mensualmente. & Si hay pérdida de datos, restaurar desde el último backup disponible. Si no hay backup, repetir el trabajo perdido priorizando lo más crítico. \\
\hline
\end{tabular}
\caption{Estrategias de Mitigación y Planes de Contingencia}
\end{table}

\subsection{Monitoreo de Riesgos}

El seguimiento de riesgos se realizará de forma continua durante todo el proyecto mediante implementación de cuatro actividades complementarias de monitoreo sistemático que operan en diferentes escalas temporales y niveles de granularidad para detectar tempranamente señales de materialización de amenazas identificadas.

La primera actividad establece revisión semanal estructurada de riesgos donde en cada reunión de seguimiento del equipo se dedicará espacio breve de 10 minutos para revisar colaborativamente si algún riesgo identificado en matriz de análisis se ha materializado parcial o totalmente durante semana transcurrida, si han surgido nuevos riesgos emergentes no contemplados inicialmente que ameriten incorporación a tabla de seguimiento, si estrategias de mitigación preventiva implementadas están funcionando efectivamente según evidencia empírica observada, y si es necesario ajustar nivel de probabilidad o impacto de riesgos existentes en función de información actualizada obtenida durante ejecución del proyecto.

La segunda actividad implementa monitoreo continuo de indicadores de alerta temprana consistentes en señales observables que indiquen proximidad creciente de materialización de riesgos específicos antes de que se manifiesten completamente, permitiendo activación proactiva de medidas correctivas anticipadas. Estos indicadores cuantitativos y cualitativos incluyen como primer indicador errores frecuentes superiores a 3 fallos diarios en ejecución de scrapers por cambios detectados en estructura HTML de portales señalizando proximidad de R01, como segundo indicador aumento progresivo en tiempo promedio de respuesta HTTP de portales objetivo superiores a 5 segundos o aparición de CAPTCHAs en sesiones de scraping alertando sobre posible R02, como tercer indicador bajo rendimiento en métricas de evaluación de NER con F1-score inferior a 60 por ciento en validación de muestras indicando materialización de R03, y como cuarto indicador retrasos acumulados superiores a 3 días en entrega de tareas asignadas según cronograma WBS señalizando activación de R06 y potencial desencadenamiento de R07 por efecto cascada.

La tercera actividad exige registro formal detallado de incidentes donde cualquier materialización confirmada de riesgo será documentada exhaustivamente en acta semanal de reunión de seguimiento mediante plantilla estructurada que indique identificador del riesgo activado según código de tabla de análisis, descripción concreta de cómo se manifestó la amenaza con evidencia empírica específica observada, acción correctiva aplicada inmediatamente especificando plan de contingencia ejecutado y recursos movilizados, integrante responsable de implementar solución y realizar seguimiento de efectividad, y resultado final obtenido cuantificando tiempo de resolución y impacto residual sobre cronograma o calidad de entregables.

La cuarta actividad establece actualización dinámica de matriz de riesgos donde si durante desarrollo del proyecto se identifica nuevo riesgo relevante no contemplado en análisis inicial que tenga probabilidad media o alta y impacto medio o alto, será agregado formalmente a tabla de identificación y clasificación con asignación de código secuencial R11 en adelante, evaluación fundamentada de probabilidad e impacto según criterios consistentes con análisis previo, categorización en tipo técnico, organizacional o infraestructura, definición de estrategia de mitigación preventiva y plan de contingencia reactivo siguiendo mismo formato que riesgos originales, y comunicación al equipo completo y asesor académico durante siguiente reunión de seguimiento para aprobación e incorporación al proceso de monitoreo continuo.

\subsection{Responsabilidades en Gestión de Riesgos}

La distribución de responsabilidades en gestión de riesgos del proyecto sigue modelo colaborativo diferenciado donde cada integrante asume liderazgo específico sobre categorías particulares de amenazas según especialización técnica y rol asignado en estructura organizacional del equipo, complementado con responsabilidades compartidas transversales que requieren participación activa de todos los miembros.

Nicolás Camacho, en su rol de líder técnico y arquitecto principal del sistema, asume responsabilidad primaria sobre identificación proactiva y monitoreo continuo de riesgos técnicos categorizados como R01 hasta R05 en matriz de análisis, incluyendo amenazas relacionadas con scraping web, rendimiento de modelos NLP, disponibilidad y calidad de datos, y complejidad de implementación de clustering semántico. Sus funciones específicas incluyen proponer soluciones técnicas fundamentadas ante materialización de riesgos de esta categoría mediante análisis de alternativas viables, coordinar aplicación operativa de estrategias de mitigación preventiva definidas ejecutando ajustes de código y configuración necesarios, y evaluar efectividad de medidas correctivas implementadas mediante análisis de métricas de desempeño y calidad de outputs generados.

Alejandro Pinzón, en su rol de coordinador de proyecto y responsable de documentación académica, asume responsabilidad primaria sobre monitoreo continuo de riesgos organizacionales categorizados como R06 hasta R08 en matriz de análisis, incluyendo amenazas relacionadas con sobrecarga académica de integrantes, retrasos acumulados en cronograma y conflictos internos de coordinación en equipo. Sus funciones específicas incluyen gestión activa del cronograma WBS verificando semanalmente cumplimiento de plazos establecidos mediante revisión de estado de tareas asignadas, detección temprana de desviaciones respecto a planificación original superior a 2 días mediante comparación entre fechas estimadas y reales de entrega, y propuesta de acciones correctivas oportunas incluyendo redistribución temporal de carga de trabajo entre integrantes o ajuste de alcance de fases no críticas para recuperar alineación con cronograma maestro.

Todo el equipo sin distinción de rol asume responsabilidades compartidas transversales consistentes en reportar inmediatamente cualquier riesgo detectado durante ejecución de tareas asignadas mediante comunicación en reunión semanal o canal urgente si criticidad lo amerita, participar activamente en evaluación colaborativa de impacto de riesgos materializados o emergentes mediante discusión estructurada fundamentada en evidencia empírica disponible, y colaborar constructivamente en implementación de planes de contingencia reactiva cuando sea necesario mediante ejecución de tareas de emergencia asignadas o soporte técnico cruzado entre integrantes para acelerar resolución de incidentes críticos.

La gestión de riesgos será proceso continuo y colaborativo ejecutado de forma integrada a actividades semanales regulares del proyecto sin constituir overhead administrativo separado, con objetivo explícito de minimizar incertidumbre asociada a amenazas identificadas mediante preparación anticipada y respuesta ágil, y maximizar probabilidad de éxito en entrega final del observatorio laboral cumpliendo estándares de calidad técnica, cronograma académico establecido y objetivos funcionales definidos en alcance del trabajo de grado.
