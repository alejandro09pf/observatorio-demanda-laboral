\chapter{INTRODUCCIÓN}

\section{Propósito}

El presente documento tiene como propósito especificar de manera detallada los requerimientos funcionales y no funcionales del sistema denominado Observatorio de Demanda Laboral en Tecnología en Latinoamérica, una herramienta de análisis automatizado orientada a procesar, extraer y segmentar habilidades tecnológicas desde portales de empleo en línea, mediante técnicas modernas de procesamiento de lenguaje natural, scraping, embeddings semánticos y clustering no supervisado.

Este documento está dirigido principalmente a tres audiencias complementarias. En primer lugar, sirve como guía estructurada para el equipo de desarrollo del proyecto, compuesto por los estudiantes \autorUno{} y \autorDos{}, orientando la implementación y validación del sistema. En segundo lugar, constituye evidencia formal del entendimiento técnico y conceptual del producto para el director del proyecto, \director{}, y los jurados evaluadores. Finalmente, proporciona un marco de referencia para otros actores académicos o institucionales interesados en replicar o adaptar el sistema en contextos similares, tales como universidades, centros de investigación o entidades públicas vinculadas al análisis del mercado laboral.

El documento cubre la totalidad del sistema propuesto, sin limitarse a un solo módulo o subsistema. Por tanto, especifica requerimientos relacionados con la adquisición de datos mediante scraping, su procesamiento semántico, análisis estadístico y segmentación por perfiles laborales, así como aspectos de validación, modularidad, documentación técnica y estándares de calidad.

La importancia de este documento radica en su papel como contrato técnico entre los actores involucrados, asegurando una visión compartida del comportamiento esperado del sistema, las restricciones existentes, los criterios de aceptación y los estándares metodológicos adoptados. Además, facilita la trazabilidad entre los objetivos definidos en la propuesta de grado y las funcionalidades implementadas en cada fase, garantizando coherencia metodológica, control de calidad y sostenibilidad del desarrollo.

\section{Alcance}

El sistema propuesto, titulado Observatorio de Demanda Laboral en Tecnología en Latinoamérica, tiene como propósito desarrollar una herramienta automatizada capaz de analizar la evolución de las habilidades tecnológicas demandadas en el mercado laboral digital, específicamente en los países de Colombia (CO), México (MX) y Argentina (AR). El sistema abarca desde la recolección periódica de datos a través de scraping en portales de empleo hasta el procesamiento semántico y la segmentación de perfiles laborales utilizando técnicas avanzadas de NLP y clustering no supervisado.

El alcance geográfico del observatorio comprende tres países latinoamericanos: Colombia, México y Argentina. Las fuentes de datos corresponden a 7 portales de empleo principales que concentran la mayor parte de las ofertas laborales tecnológicas en la región, incluyendo Computrabajo, Bumeran, ElEmpleo, HiringCafe, OCC Mundial, ZonaJobs e Indeed.

La taxonomía base del sistema constituye una integración unificada de 14,174 habilidades, compuesta por 13,939 competencias de la base europea ESCO v1.1.0, complementadas con 152 tecnologías emergentes del catálogo O*NET Hot Technologies del sector IT, y 83 habilidades curadas manualmente específicas para el mercado tecnológico latinoamericano. El stack tecnológico seleccionado incluye Python 3.10 o superior como lenguaje base, Scrapy para extracción automatizada, spaCy para procesamiento de lenguaje natural, PostgreSQL como sistema de gestión de base de datos, FAISS para búsqueda vectorial eficiente, el modelo de embeddings multilingües E5 de 768 dimensiones, y los algoritmos HDBSCAN y UMAP para clustering y reducción dimensional respectivamente.

El producto incluye siete funcionalidades principales integradas en un pipeline secuencial. La primera funcionalidad corresponde a la extracción automatizada de vacantes desde los portales web mediante spiders especializados que respetan las normas de uso de cada sitio. La segunda funcionalidad implementa preprocesamiento y limpieza textual mediante tokenización, lematización y normalización de formatos, preparando los datos para análisis posterior. La tercera funcionalidad ejecuta la detección de habilidades explícitas e implícitas mediante técnicas híbridas que combinan reconocimiento de entidades nombradas, expresiones regulares y modelos de lenguaje.

La cuarta funcionalidad genera representaciones semánticas mediante el modelo de embeddings E5 de 768 dimensiones, seguido de reducción dimensional con UMAP para visualización y agrupación eficiente. La quinta funcionalidad mapea las habilidades extraídas contra la taxonomía ESCO mediante una estrategia de tres capas que incluye matching exacto, fuzzy matching con umbral de similitud del 85 por ciento, y semantic matching mediante búsqueda vectorial con FAISS. La sexta funcionalidad agrupa perfiles laborales mediante el algoritmo HDBSCAN, que permite segmentar la demanda en grupos funcionales coherentes sin requerir especificación previa del número de clusters. La séptima funcionalidad genera visualizaciones macro mediante gráficos interpretables y reportes estáticos, complementados por un dashboard web interactivo desarrollado con Next.js que permite consulta dinámica de métricas y tendencias. Finalmente, el sistema proporciona documentación metodológica completa y código reproducible que permite replicar o adaptar la solución a otras regiones o sectores bajo principios de ética, apertura científica y eficiencia computacional.

El alcance funcional se circunscribe al dominio de las ofertas de empleo tecnológicas publicadas en español en los países mencionados, sin contemplar vacantes en otros idiomas ni otros sectores económicos. Sin embargo, el diseño modular del sistema permitirá su adaptación futura a nuevos contextos geográficos o temáticos.

\section{Definiciones, Acrónimos y Abreviaciones}

\subsection{Portales de empleo}
Son plataformas web donde empresas publican vacantes laborales y profesionales buscan oportunidades. En este proyecto se consideran fuentes como LinkedIn, Computrabajo, Bumeran, ZonaJobs e Indeed, que constituyen insumos primarios para los procesos de scraping y análisis \cite{aguilera2018, cardenas2015}.

\subsection{Web Scraping}
Técnica de recolección automatizada de datos desde páginas web, utilizando librerías como BeautifulSoup, Selenium o Playwright. Permite extraer de forma estructurada información relevante de las ofertas publicadas \cite{orozco2019}.

\subsection{Oferta laboral}
Se refiere al anuncio publicado por una organización donde se describe el perfil buscado, incluyendo título del cargo, funciones, requisitos y habilidades deseadas \cite{rubio2024}.

\subsection{Base de datos relacional (PostgreSQL)}
Sistema que organiza los datos recolectados en tablas interconectadas, facilitando su consulta, limpieza y posterior análisis mediante estructuras SQL \cite{martinez2024}.

\subsection{Normalización de datos}
Proceso de limpieza, estandarización y unificación de formatos para reducir ambigüedad, errores y duplicados, y mejorar la coherencia del análisis posterior \cite{martinez2024}.

\subsection{Expresiones regulares (Regex)}
Lenguaje sintáctico utilizado para identificar y extraer patrones textuales específicos (como frases que contengan habilidades o requisitos) en grandes volúmenes de texto.

\subsection{Named Entity Recognition (NER)}
Técnica de procesamiento de lenguaje natural (NLP) que identifica y clasifica entidades en un texto, como nombres de habilidades, empresas o tecnologías \cite{vasquez2024, aitoskillner}.

\subsection{Tokenización}
Consiste en dividir un texto en unidades mínimas llamadas ``tokens'' (palabras, signos u oraciones), facilitando el análisis lingüístico automatizado.

\subsection{Lematización}
Proceso que transforma las palabras a su forma canónica o raíz gramatical, permitiendo uniformar variaciones morfológicas del lenguaje.

\subsection{Stopwords}
Términos frecuentes sin valor informativo (como ``de'', ``por'', ``la''), comúnmente eliminados en tareas de procesamiento textual.

\subsection{Co-ocurrencia}
Medida estadística que indica la frecuencia con que dos o más términos aparecen juntos en un texto, útil para detectar relaciones semánticas \cite{lukauskas2023}.

\subsection{Bigramas y trigramas}
Secuencias de dos o tres palabras consecutivas utilizadas para capturar patrones de lenguaje más complejos que las palabras individuales.

\subsection{LLM (Large Language Models)}
Modelos de lenguaje de gran escala (como GPT o T5) entrenados sobre corpus masivos, capaces de generar texto, extraer conocimiento implícito y realizar razonamiento contextualizado \cite{nguyen2024}.

\subsection{Prompt Engineering}
Diseño estratégico de instrucciones o ejemplos para guiar la salida de un LLM, crucial en tareas de extracción de habilidades o clasificación de ocupaciones \cite{nguyen2024}.

\subsection{Few-shot learning}
Habilidad de los LLMs para realizar tareas complejas con pocos ejemplos, lo cual resulta clave cuando se carece de datasets etiquetados masivamente en español \cite{nguyen2024}.

\subsection{Embeddings semánticos}
Representaciones numéricas de textos que capturan similitudes semánticas, permitiendo análisis cuantitativos y clustering. Ejemplos incluyen word2vec, BERT y E5 \cite{kavas2024}.

\subsection{Embeddings multilingües}
Vectores entrenados para representar texto en múltiples idiomas en un mismo espacio semántico. Son esenciales para manejar contenido mixto español-inglés en ofertas laborales \cite{kavas2025}.

\subsection{UMAP (Reducción de dimensionalidad)}
Técnica que transforma espacios de alta dimensionalidad en representaciones más simples, conservando la estructura semántica subyacente para facilitar análisis y visualización.

\subsection{Clustering (HDBSCAN)}
Algoritmo no supervisado que detecta grupos naturales de observaciones (como habilidades o perfiles laborales) según su similitud semántica, sin requerir número de clusters predefinido \cite{lukauskas2023}.

\subsection{Taxonomía de habilidades (ESCO, CIUO-08, O*NET)}
Sistemas jerárquicos y normalizados de clasificación de habilidades y ocupaciones, fundamentales para anclar el análisis a estándares internacionales y mejorar interoperabilidad de los resultados \cite{echeverria2022, campos2024}.

\subsection{FAISS (Facebook AI Similarity Search)}
Biblioteca de código abierto para búsqueda eficiente de similitud en espacios vectoriales de alta dimensionalidad. El sistema utiliza FAISS IndexFlatIP para búsqueda exacta de vecinos más cercanos con producto interno, logrando velocidades de 30,147 consultas por segundo, aproximadamente 25 veces más rápido que PostgreSQL con pgvector.

\subsection{Estrategia de tres capas (Three-layer matching)}
Metodología implementada para mapear habilidades extraídas contra la taxonomía ESCO:
\begin{itemize}
    \item Layer 1 - Exact Match: Búsqueda exacta mediante SQL ILIKE con confianza 1.0
    \item Layer 2 - Fuzzy Match: Similitud difusa con fuzzywuzzy, threshold 0.85, confianza 0.85-1.0
    \item Layer 3 - Semantic Match: Búsqueda semántica con FAISS, threshold 0.87, confianza 0.87-1.0 (actualmente deshabilitado debido a limitaciones del modelo E5 con vocabulario técnico)
\end{itemize}

\subsection{Skills emergentes}
Habilidades extraídas de ofertas laborales que no pueden ser mapeadas a la taxonomía ESCO existente. Representan el 87.4\% de las skills extraídas y constituyen una señal valiosa sobre tendencias emergentes del mercado tech latinoamericano, no un fallo del sistema.

\subsection{Natural Language Processing (NLP)}
Conjunto de técnicas de inteligencia artificial, combinando modelos de lingüística computacional, machine learning y aprendizaje profundo, para poder procesar lenguaje humano.

\subsection{Python}
Lenguaje de programación ampliamente utilizado en ciencia de datos y NLP, por su sintaxis sencilla y librerías especializadas como scikit-learn, spaCy, transformers y pandas.

\section{Apreciación Global}

El presente documento de Especificación de Requerimientos del Software tiene como objetivo presentar de manera estructurada y detallada los aspectos fundamentales del sistema Observatorio de Demanda Laboral en Tecnología en Latinoamérica. La organización del documento se ha realizado con el propósito de facilitar su comprensión tanto para usuarios técnicos como no técnicos, brindando una visión progresiva desde el contexto general hasta los requerimientos específicos del sistema.

El contenido del documento se distribuye en tres secciones principales. La Sección 1 expone la introducción general del proyecto, incluyendo su propósito, alcance, definiciones clave, referencias utilizadas y una apreciación global de su contenido. La Sección 2 describe de manera general los factores que afectan al producto, incluyendo su perspectiva dentro del ecosistema tecnológico, interfaces con otros sistemas y con el usuario, consideraciones de hardware y software, restricciones operativas, y requerimientos de adaptación al entorno de despliegue. La Sección 3 presenta los requerimientos funcionales y no funcionales del sistema, detallando exhaustivamente cada funcionalidad esperada, las restricciones técnicas y operativas, las condiciones necesarias para su correcto funcionamiento, los criterios de validación y verificación, los atributos de calidad del software, los requerimientos de base de datos, la trazabilidad entre objetivos y requerimientos, y el estado actual de implementación de cada módulo del sistema.

Este documento servirá como base para el diseño, desarrollo, validación y evaluación del sistema propuesto, asegurando que todos los actores involucrados compartan una visión clara y consensuada de los objetivos, alcances y funcionalidades del software a implementar. Además, constituye un instrumento de trazabilidad que permite verificar el cumplimiento de cada requerimiento especificado durante el ciclo de vida del proyecto.

% ============================================================================
