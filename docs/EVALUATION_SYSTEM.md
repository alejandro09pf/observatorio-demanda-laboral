# Sistema de EvaluaciÃ³n de Pipelines

**Ãšltima actualizaciÃ³n:** 2025-11-05

---

## ğŸ“¦ QUÃ‰ SE IMPLEMENTÃ“

### MÃ³dulo Core: `src/evaluation/`

**1. `normalizer.py` (368 lÃ­neas)**
- NormalizaciÃ³n unificada de skills
- Diccionario canÃ³nico con 200+ tecnologÃ­as
- Maneja variantes: `postgres`â†’`PostgreSQL`, `js`â†’`JavaScript`, `k8s`â†’`Kubernetes`
- Blacklist de tÃ©rminos no-skills
- Singleton pattern para performance

**2. `metrics.py` (260 lÃ­neas)**
- CÃ¡lculo de mÃ©tricas: Precision, Recall, F1-Score, Accuracy
- Confusion Matrix: TP, FP, TN, FN
- Micro/Macro averaging
- Listas detalladas de errores (TP, FP, FN)

**3. `dual_comparator.py` (630 lÃ­neas)**
- **Modo 1:** ComparaciÃ³n vs Gold Standard
  - Texto normalizado (sin bias ESCO)
  - Post-mapeo ESCO (fairness - mismo cÃ³digo)
  - AnÃ¡lisis de impacto ESCO
- **Modo 2:** ComparaciÃ³n head-to-head de LLMs
  - Overlap (Jaccard similarity)
  - EstadÃ­sticas agregadas
- **Modo 3:** AnÃ¡lisis descriptivo sin gold standard
  - Stats bÃ¡sicas + cobertura ESCO

### Script: `scripts/evaluate_pipelines.py`

UN SOLO script que soporta 3 modos de evaluaciÃ³n.

---

## ğŸš€ CÃ“MO USAR

### **MODO 1: Gold Standard** (EvaluaciÃ³n Completa)

Compara pipelines contra el gold standard de 300 jobs anotados.

```bash
# Evaluar Pipeline A + mÃºltiples LLMs (todas las skills)
python scripts/evaluate_pipelines.py \
  --mode gold-standard \
  --pipelines pipeline-a llama-3.2-3b-instruct gemma-3-4b-instruct qwen2.5-3b-instruct

# Solo Pipeline A
python scripts/evaluate_pipelines.py \
  --mode gold-standard \
  --pipelines pipeline-a

# Solo LLMs
python scripts/evaluate_pipelines.py \
  --mode gold-standard \
  --pipelines llama-3.2-3b-instruct gemma-3-4b-instruct

# Evaluar solo hard skills
python scripts/evaluate_pipelines.py \
  --mode gold-standard \
  --pipelines pipeline-a llama-3.2-3b-instruct \
  --skill-type hard

# Evaluar hard y soft por separado (genera 2 reportes)
python scripts/evaluate_pipelines.py \
  --mode gold-standard \
  --pipelines pipeline-a llama-3.2-3b-instruct \
  --skill-type both
```

**Output:**
- `EVALUATION_REPORT_<timestamp>.md` - Reporte ejecutivo
- `comparison_pure_<timestamp>.csv` - MÃ©tricas sin ESCO
- `comparison_esco_<timestamp>.csv` - MÃ©tricas post-ESCO
- `evaluation_<timestamp>.json` - Datos completos

**Incluye:**
1. ComparaciÃ³n 1: Texto normalizado (sin mapeo ESCO)
2. ComparaciÃ³n 2: Post-mapeo ESCO (mismo cÃ³digo para todos)
3. AnÃ¡lisis de impacto ESCO (Î” F1, skills perdidas)
4. Skills emergentes identificadas (no en ESCO)

---

### **MODO 2: LLM Comparison** (Head-to-Head)

Compara mÃºltiples LLMs entre sÃ­ sin gold standard.

```bash
python scripts/evaluate_pipelines.py \
  --mode llm-comparison \
  --llm-models llama-3.2-3b gemma-3-4b qwen2.5-3b mistral-7b phi-3.5
```

**Output:**
- `LLM_COMPARISON_<timestamp>.md` - Reporte de comparaciÃ³n
- `llm_comparison_<timestamp>.json` - Datos completos

**Incluye:**
- Stats por modelo: total skills, unique skills, avg/job
- Overlap entre modelos (Jaccard similarity)
- Skills en comÃºn vs Ãºnicos

---

### **MODO 3: Descriptive** (AnÃ¡lisis sin Gold Standard)

Analiza un pipeline sin comparaciÃ³n.

```bash
# Analizar Pipeline A
python scripts/evaluate_pipelines.py \
  --mode descriptive \
  --pipeline pipeline-a

# Analizar un LLM
python scripts/evaluate_pipelines.py \
  --mode descriptive \
  --pipeline llama-3.2-3b-instruct
```

**Output:**
- `DESCRIPTIVE_<pipeline>_<timestamp>.md` - Reporte descriptivo
- `descriptive_<pipeline>_<timestamp>.json` - Datos

**Incluye:**
- Total jobs, skills extraÃ­dos, unique skills
- Avg skills/job
- Cobertura ESCO (% mapeados)
- Skills no mapeados (sample)

---

## ğŸ“Š ESTRUCTURA DE LOS REPORTES

### Reporte Gold Standard

```markdown
# EvaluaciÃ³n de Pipelines vs Gold Standard

## 1. ExtracciÃ³n Pura (Sin Mapeo ESCO)
| Pipeline           | Precision | Recall | F1-Score |
|--------------------|-----------|--------|----------|
| Pipeline A         | 0.85      | 0.78   | 0.81     |
| Pipeline B (Llama) | 0.88      | 0.82   | 0.85     |

**Ganador:** Pipeline B (F1=0.85)

## 2. Post-Mapeo ESCO
| Pipeline           | Precision | Recall | F1-Score | Cobertura ESCO |
|--------------------|-----------|--------|----------|----------------|
| Pipeline A         | 0.82      | 0.71   | 0.76     | 85%            |
| Pipeline B (Llama) | 0.85      | 0.75   | 0.80     | 89%            |

**Ganador:** Pipeline B (F1=0.80)

## 3. Impacto del Mapeo a ESCO
| Pipeline           | Î” F1     | Î” F1 (%) | Skills Perdidas |
|--------------------|----------|----------|-----------------|
| Pipeline A         | -0.0500  | -6.17%   | 4               |
| Pipeline B (Llama) | -0.0500  | -5.88%   | 3               |

## 4. Skills Emergentes (No en ESCO)
**Total:** 15

- Next.js
- Tailwind CSS
- FastAPI
- ...
```

---

## ğŸ¯ CASOS DE USO

### Caso 1: Evaluar Pipeline A vs mÃºltiples LLMs

**Objetivo:** Determinar si LLMs son mejores que NER+Regex

```bash
python scripts/evaluate_pipelines.py \
  --mode gold-standard \
  --pipelines pipeline-a llama-3.2-3b gemma-3-4b qwen2.5-3b qwen3-4b
```

**Resultado esperado:**
- ComparaciÃ³n P/R/F1 para cada pipeline
- Identificar cuÃ¡l extrae mejor
- Ver impacto de ESCO en cada uno

---

### Caso 2: Comparar LLMs entre sÃ­ (sin gold standard)

**Objetivo:** Ver quÃ© LLMs extraen mÃ¡s/menos skills, overlap

```bash
python scripts/evaluate_pipelines.py \
  --mode llm-comparison \
  --llm-models llama-3.2-3b gemma-3-4b qwen2.5-3b mistral-7b
```

**Resultado esperado:**
- Stats por LLM
- Overlap (Â¿extraen las mismas skills?)
- Identificar outliers

---

### Caso 3: AnÃ¡lisis descriptivo de Pipeline A

**Objetivo:** Ver stats generales sin comparaciÃ³n

```bash
python scripts/evaluate_pipelines.py \
  --mode descriptive \
  --pipeline pipeline-a
```

**Resultado esperado:**
- Total skills, unique, avg/job
- Cobertura ESCO
- Skills emergentes

---

## ğŸ”§ REQUISITOS

### Base de Datos

**Para Modo Gold Standard:**
- Tabla `gold_standard_annotations` con 300 jobs anotados âœ…
  - 7,848 skills totales (6,174 hard + 1,674 soft)
- Tabla `extracted_skills` con resultados de Pipeline A
- Tabla `enhanced_skills` con resultados de Pipeline B (por LLM)

**Para otros modos:**
- Solo `extracted_skills` o `enhanced_skills` segÃºn corresponda

### EjecuciÃ³n de Pipelines

Este sistema **NO ejecuta los pipelines**, solo los evalÃºa.

Debes ejecutar los pipelines usando tu mÃ©todo habitual (orchestrator, scripts, etc.)

---

## ğŸ“ METODOLOGÃA DE EVALUACIÃ“N DETALLADA

### Proceso de EvaluaciÃ³n en 3 Pasos

El sistema implementa un proceso de evaluaciÃ³n dual que permite responder tanto a la pregunta de **capacidad de extracciÃ³n** como de **estandarizaciÃ³n**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  PASO 1: COMPARACIÃ“N PRE-ESCO                   â”‚
â”‚          (ValidaciÃ³n de capacidad de extracciÃ³n pura)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
         Gold Standard (texto)  â†â†’  Pipeline (texto)
                              â†“
              NormalizaciÃ³n + Text Matching
                              â†“
         MÃ©tricas: Precision, Recall, F1-Score
         âœ… Captura skills emergentes (Next.js, Tailwind)


â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  PASO 2: MAPEO A ESCO (FAIRNESS)                â”‚
â”‚           (Todos los pipelines con MISMO cÃ³digo)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
         Re-mapear: Gold Standard â†’ ESCO URIs
         Re-mapear: Pipeline â†’ ESCO URIs
                              â†“
              ESCOMatcher3Layers (mismo para todos)
                              â†“
         âš ï¸  Skills emergentes se pierden (no mapean)


â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 PASO 3: COMPARACIÃ“N POST-ESCO                   â”‚
â”‚             (ValidaciÃ³n de estandarizaciÃ³n)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
         Gold ESCO URIs  â†â†’  Pipeline ESCO URIs
                              â†“
                    URI Matching Exacto
                              â†“
         MÃ©tricas: Precision, Recall, F1-Score
         + Cobertura ESCO (% mapeado)


â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  PASO 4: ANÃLISIS DE IMPACTO                    â”‚
â”‚          (Trade-off: Flexibilidad vs EstandarizaciÃ³n)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
         Î” F1 = F1_post_esco - F1_pre_esco
         Skills Perdidas = Emergentes no mapeadas
         Skills Emergentes (listado completo)
```

---

### Â¿CÃ³mo funciona la validaciÃ³n PRE-ESCO?

**Pregunta comÃºn:** *"Estamos contrastando texto aleatorio con texto aleatorio?"*

**Respuesta:** No. Usamos normalizaciÃ³n inteligente + text matching:

#### 1. NormalizaciÃ³n CanÃ³nica (`normalizer.py`)

Diccionario con **200+ tecnologÃ­as** en forma canÃ³nica:

```python
CANONICAL_FORMS = {
    'python': 'Python',
    'javascript': 'JavaScript',
    'js': 'JavaScript',
    'postgres': 'PostgreSQL',
    'postgresql': 'PostgreSQL',
    'k8s': 'Kubernetes',
    'kubernetes': 'Kubernetes',
    # ... 200+ mappings
}
```

**Proceso:**
1. Gold Standard skill: `"postgres"` â†’ Normalizado: `"PostgreSQL"`
2. Pipeline extrae: `"PostgreSQL"` â†’ Normalizado: `"PostgreSQL"`
3. **Match exacto** âœ…

#### 2. Validez del Approach

**Â¿Es vÃ¡lido comparar texto normalizado sin ESCO?**

âœ… **SÃ, en el contexto de tech jobs:**

**Pros:**
- TecnologÃ­as tienen nombres estÃ¡ndar (Python, React, Docker)
- AmbigÃ¼edad es rara en avisos tech
- Captura skills emergentes que ESCO no tiene
- No sesga por coverage de ESCO

**Contras:**
- SinÃ³nimos raros pueden no matchear (ej: `Machine Learning` vs `ML`)
- SoluciÃ³n: diccionario canÃ³nico cubre casos comunes

**JustificaciÃ³n para tesis:**
- EvalÃºa **capacidad de extracciÃ³n** sin penalizar innovaciÃ³n
- Complementado por validaciÃ³n post-ESCO para estandarizaciÃ³n
- Permite identificar skills emergentes para actualizar ESCO

---

### Â¿CÃ³mo se manejan las Skills Emergentes?

**Skills emergentes** = Skills NO en taxonomÃ­a ESCO (14,174 skills)

Ejemplos: `Next.js`, `Tailwind CSS`, `FastAPI`, `Svelte`, `Vite`

#### Flujo Completo:

**En PRE-ESCO:**
```
Gold Standard: ["Python", "Next.js", "PostgreSQL"]
Pipeline extrae: ["Python", "Next.js", "React"]

â†’ NormalizaciÃ³n:
  Gold: {"Python", "Next.js", "PostgreSQL"}
  Pipeline: {"Python", "Next.js", "React"}

â†’ Matching:
  TP: {"Python", "Next.js"}  â† Next.js cuenta como TP âœ…
  FN: {"PostgreSQL"}
  FP: {"React"}

â†’ Precision = 2/3 = 0.67
â†’ Recall = 2/3 = 0.67
```

**En MAPEO A ESCO:**
```
Gold: ["Python", "Next.js", "PostgreSQL"]
â†’ ESCO Mapper:
  "Python" â†’ http://data.europa.eu/esco/skill/abc123
  "Next.js" â†’ None (no existe en ESCO) âŒ
  "PostgreSQL" â†’ http://data.europa.eu/esco/skill/def456

Gold ESCO: {abc123, def456}  â† Next.js desaparece


Pipeline: ["Python", "Next.js", "React"]
â†’ ESCO Mapper:
  "Python" â†’ http://data.europa.eu/esco/skill/abc123
  "Next.js" â†’ None âŒ
  "React" â†’ http://data.europa.eu/esco/skill/ghi789

Pipeline ESCO: {abc123, ghi789}  â† Next.js desaparece
```

**En POST-ESCO:**
```
Gold ESCO: {abc123, def456}
Pipeline ESCO: {abc123, ghi789}

â†’ TP: {abc123} (Python)
â†’ FN: {def456} (PostgreSQL)
â†’ FP: {ghi789} (React)

â†’ Precision = 1/2 = 0.50
â†’ Recall = 1/2 = 0.50

âš ï¸ Next.js ya no afecta las mÃ©tricas (eliminado de ambos)
```

**En ANÃLISIS DE IMPACTO:**
```
Î” F1 = 0.50 - 0.67 = -0.17 (-25%)
Skills Perdidas = 1 (Next.js)
Skills Emergentes: ["Next.js"]
```

#### Reporte Final

```markdown
## 3. Impacto del Mapeo a ESCO
| Pipeline | Î” F1    | Skills Perdidas |
|----------|---------|-----------------|
| Pipeline | -0.17   | 1               |

## 4. Skills Emergentes (No en ESCO)
**Total:** 1

- Next.js
```

**InterpretaciÃ³n:**
- Pre-ESCO: F1=0.67 â†’ Pipeline extrae bien, incluyendo skills modernas
- Post-ESCO: F1=0.50 â†’ EstandarizaciÃ³n tiene costo (pierde Next.js)
- Trade-off: Flexibilidad vs EstandarizaciÃ³n explÃ­cito

---

### EvaluaciÃ³n por Tipo de Skill (Hard vs Soft)

El sistema soporta evaluar **hard skills** y **soft skills** por separado:

#### Uso:

```bash
# Evaluar todas las skills juntas (default)
python scripts/evaluate_pipelines.py \
  --mode gold-standard \
  --pipelines pipeline-a llama-3.2-3b-instruct \
  --skill-type all

# Evaluar solo hard skills
python scripts/evaluate_pipelines.py \
  --mode gold-standard \
  --pipelines pipeline-a llama-3.2-3b-instruct \
  --skill-type hard

# Evaluar solo soft skills
python scripts/evaluate_pipelines.py \
  --mode gold-standard \
  --pipelines pipeline-a llama-3.2-3b-instruct \
  --skill-type soft

# Evaluar ambas por separado (genera 2 reportes)
python scripts/evaluate_pipelines.py \
  --mode gold-standard \
  --pipelines pipeline-a llama-3.2-3b-instruct \
  --skill-type both
```

#### Output con `--skill-type both`:

Genera **2 reportes separados**:
- `EVALUATION_REPORT_hard_<timestamp>.md` - Solo hard skills
- `EVALUATION_REPORT_soft_<timestamp>.md` - Solo soft skills

Cada reporte incluye:
- ComparaciÃ³n Pre-ESCO (solo skills del tipo filtrado)
- ComparaciÃ³n Post-ESCO (solo skills del tipo filtrado)
- Impacto ESCO
- Skills emergentes del tipo

**Ejemplo:**

```markdown
# EvaluaciÃ³n de Pipelines vs Gold Standard (hard)

**Jobs evaluados:** 300
**Skill type:** hard
**Skills en gold standard:** 6,174

## 1. ExtracciÃ³n Pura (Sin Mapeo ESCO)
| Pipeline | Precision | Recall | F1-Score |
|----------|-----------|--------|----------|
| Pipeline A | 0.85 | 0.78 | 0.81 |
...
```

#### ImplementaciÃ³n:

El sistema filtra skills por tipo **antes** de la comparaciÃ³n:

```python
# En dual_comparator.py
filtered_gold = gold_standard.filter_by_type('hard')
filtered_pipeline = pipeline.filter_by_type('hard')

# Solo skills hard participan en mÃ©tricas
```

**Ventaja:** Permite analizar si los pipelines extraen mejor hard o soft skills.

---

## ğŸ’¡ DECISIONES DE DISEÃ‘O

### 1. Doble ComparaciÃ³n (Texto + ESCO)

**ComparaciÃ³n 1: Texto Normalizado**
- EvalÃºa capacidad de extracciÃ³n pura
- No penaliza skills emergentes (Next.js, Tailwind, etc.)
- Fairness: no sesga por ESCO

**ComparaciÃ³n 2: Post-Mapeo ESCO**
- Re-mapea todos los pipelines con el MISMO cÃ³digo
- Pipeline A se re-mapea (no usa su mapeo existente)
- EvalÃºa estandarizaciÃ³n
- Identifica skills no mapeables

**Â¿Por quÃ© ambas?**
- Responde 2 preguntas distintas:
  1. Â¿QuÃ© extrae mejor? (sin ESCO)
  2. Â¿QuÃ© estandariza mejor? (con ESCO)

### 2. NormalizaciÃ³n Unificada

**Problema:** Skills pueden tener variaciones (Python vs python vs PYTHON)

**SoluciÃ³n:** Diccionario canÃ³nico + reglas de normalizaciÃ³n

**AplicaciÃ³n:** Todos los pipelines se normalizan igual antes de comparar

### 3. Flexibilidad de Modos

**Problema:** No siempre tienes gold standard disponible

**SoluciÃ³n:** 3 modos independientes segÃºn quÃ© tengas disponible

---

## ğŸ“ ARCHIVOS DEL SISTEMA

```
src/evaluation/
â”œâ”€â”€ __init__.py              # Exports
â”œâ”€â”€ normalizer.py            # NormalizaciÃ³n unificada (368 lÃ­neas)
â”œâ”€â”€ metrics.py               # CÃ¡lculo de mÃ©tricas (260 lÃ­neas)
â””â”€â”€ dual_comparator.py       # Comparador multi-modo (630 lÃ­neas)

scripts/
â””â”€â”€ evaluate_pipelines.py    # Script Ãºnico de evaluaciÃ³n (400 lÃ­neas)

docs/
â”œâ”€â”€ EVALUATION_SYSTEM.md     # Esta documentaciÃ³n
â””â”€â”€ EVALUATION_IMPLEMENTATION_LOG.md  # Log detallado
```

**Total:** ~1,658 lÃ­neas de cÃ³digo + documentaciÃ³n

---

## âœ… CHECKLIST DE USO

### Antes de Evaluar

- [ ] Tienes gold standard en `gold_standard_annotations` (solo modo 1)
- [ ] Ejecutaste Pipeline A en los jobs que quieres evaluar
- [ ] Ejecutaste Pipeline B (LLMs) en los jobs que quieres evaluar
- [ ] Los jobs estÃ¡n en `extracted_skills` y/o `enhanced_skills`

### Ejecutar EvaluaciÃ³n

- [ ] Elegiste el modo apropiado (gold-standard, llm-comparison, descriptive)
- [ ] Especificaste los pipelines/LLMs correctos
- [ ] Verificaste el output directory

### DespuÃ©s de Evaluar

- [ ] Revisaste el reporte Markdown
- [ ] Verificaste las mÃ©tricas hacen sentido
- [ ] Exportaste CSV si necesitas procesar mÃ¡s

---

## â“ FAQ

**P: Â¿CÃ³mo ejecuto los pipelines?**
R: Este sistema NO ejecuta pipelines, solo los evalÃºa. Usa tu mÃ©todo habitual (orchestrator, scripts propios, etc.)

**P: Â¿Puedo evaluar sin gold standard?**
R: SÃ­, usa modo `llm-comparison` o `descriptive`

**P: Â¿QuÃ© es "Pipeline A"?**
R: Pipeline A = NER + Regex + ESCO. Sus resultados estÃ¡n en tabla `extracted_skills`

**P: Â¿CÃ³mo especifico un LLM?**
R: Usa el nombre del modelo como aparece en `llm_model` column de `enhanced_skills`

**P: Â¿El mapeo a ESCO es justo?**
R: SÃ­, todos los pipelines se re-mapean con el MISMO cÃ³digo (`ESCOMatcher3Layers`)

**P: Â¿Puedo comparar Pipeline A vs Pipeline A?**
R: No tiene sentido, pero tÃ©cnicamente funciona

**P: Â¿Los reportes se sobreescriben?**
R: No, cada ejecuciÃ³n crea archivos con timestamp Ãºnico

---

## ğŸ¯ PRÃ“XIMOS PASOS

Este sistema estÃ¡ **completo y listo para usar**.

Opcionales (si necesitas):
- Visualizaciones (grÃ¡ficos matplotlib/seaborn)
- AnÃ¡lisis por contexto (portal, paÃ­s, tipo de skill)
- Export a otros formatos
- IntegraciÃ³n con notebooks Jupyter

---

**Para cualquier duda, revisa el cÃ³digo - estÃ¡ documentado.**
