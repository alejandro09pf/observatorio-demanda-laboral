# Propuesta de Integraci√≥n: Arquitectura del Sistema
## Reestructuraci√≥n de la Secci√≥n 6.3 del Documento Principal

---

## üìã Estructura Propuesta

### **Secci√≥n 6.3: Arquitectura del Sistema** (Reemplazar completamente)

```
6.3 Arquitectura del Sistema .................................................. XX
    6.3.1 Modelo de Vistas Arquitect√≥nicas .................................. XX
    6.3.2 Vista L√≥gica: Componentes y Patrones Arquitect√≥nicos ............. XX
          6.3.2.1 Patr√≥n H√≠brido Implementado .............................. XX
          6.3.2.2 Los Siete Servicios del Sistema .......................... XX
          6.3.2.3 Patrones de Comunicaci√≥n: Request/Response y Pub/Sub .... XX
    6.3.3 Vista F√≠sica: Infraestructura y Despliegue ....................... XX
          6.3.3.1 Especificaciones del Servidor ............................ XX
          6.3.3.2 Contenedores Docker y Orquestaci√≥n ....................... XX
          6.3.3.3 Configuraci√≥n de Red y Vol√∫menes ......................... XX
    6.3.4 Vista de Procesos: Ejecuci√≥n y Concurrencia ..................... XX
          6.3.4.1 Pipeline CRISP-DM y Flujo de Procesamiento ............... XX
          6.3.4.2 Escalabilidad Horizontal de Workers ...................... XX
          6.3.4.3 Gesti√≥n de Tareas As√≠ncronas ............................. XX
    6.3.5 Integraci√≥n de Vistas: Arquitectura Completa ..................... XX
    6.3.6 Dise√±o de la Base de Datos ....................................... XX
```

---

## üìù Texto Propuesto para Cada Subsecci√≥n

### **6.3 Arquitectura del Sistema**

El dise√±o arquitect√≥nico del Observatorio de Demanda Laboral requiere una documentaci√≥n multinivel que capture tanto la estructura l√≥gica del sistema como su despliegue f√≠sico y comportamiento en tiempo de ejecuci√≥n. Para lograr una especificaci√≥n completa y no ambigua, se adopt√≥ el **Modelo 4+1 de Vistas Arquitect√≥nicas** propuesto por Kruchten (1995), el cual permite describir la arquitectura desde m√∫ltiples perspectivas complementarias, cada una enfocada en las preocupaciones de diferentes stakeholders del proyecto.

Este modelo organiza la arquitectura en cuatro vistas principales m√°s una vista de escenarios:

1. **Vista L√≥gica**: Describe la funcionalidad que el sistema proporciona a los usuarios finales mediante la descomposici√≥n en componentes y sus relaciones
2. **Vista de Procesos**: Aborda aspectos de concurrencia, distribuci√≥n, integraci√≥n, rendimiento y escalabilidad del sistema
3. **Vista F√≠sica** (Deployment): Mapea el software sobre el hardware y muestra la distribuci√≥n f√≠sica de los componentes
4. **Vista de Desarrollo**: Describe la organizaci√≥n est√°tica del software en su ambiente de desarrollo
5. **Vista de Escenarios** (+1): Ilustra el comportamiento del sistema mediante casos de uso concretos

Para el presente proyecto, se documentan tres de estas vistas: **L√≥gica, F√≠sica y de Procesos**, que en conjunto proporcionan una especificaci√≥n completa de la arquitectura implementada. La Vista de Desarrollo se omite por estar fuera del alcance de este documento acad√©mico, mientras que los escenarios de uso se abordan en el Cap√≠tulo 8 (Resultados) mediante casos de estudio espec√≠ficos.

Las siguientes subsecciones presentan cada vista arquitect√≥nica, comenzando con la estructura l√≥gica del sistema, seguida de su despliegue f√≠sico, y culminando con los aspectos din√°micos de ejecuci√≥n y procesamiento distribuido.

---

### **6.3.1 Modelo de Vistas Arquitect√≥nicas**

#### Justificaci√≥n del Modelo de Vistas

La complejidad inherente del sistema ‚Äî que combina procesamiento s√≠ncrono de baja latencia para consultas de usuarios con procesamiento as√≠ncrono distribuido de tareas computacionalmente intensivas ‚Äî requiere m√∫ltiples perspectivas para su documentaci√≥n completa. Una sola vista arquitect√≥nica resultar√≠a insuficiente para capturar simult√°neamente:

- La descomposici√≥n funcional del sistema en servicios especializados
- El mapeo de estos servicios sobre contenedores Docker e infraestructura f√≠sica
- Los flujos de ejecuci√≥n y procesamiento paralelo de datos
- Las decisiones de escalabilidad y tolerancia a fallos

El Modelo 4+1 de Kruchten proporciona un marco probado industrialmente para organizar estas perspectivas de forma coherente y sistem√°tica.

#### Vistas Documentadas

**Vista L√≥gica** (Secci√≥n 6.3.2):
- Enfoque: Funcionalidad y responsabilidades de cada componente
- Audiencia: Arquitectos de software, desarrolladores
- Artefactos: Diagramas de componentes, patrones arquitect√≥nicos
- Notaci√≥n: C4 Model - Container Level + diagramas UML de componentes

**Vista F√≠sica** (Secci√≥n 6.3.3):
- Enfoque: Topolog√≠a de despliegue, infraestructura, configuraci√≥n de red
- Audiencia: DevOps, administradores de sistemas, ingenieros de infraestructura
- Artefactos: Diagramas de despliegue, especificaciones de hardware
- Notaci√≥n: UML Deployment Diagrams

**Vista de Procesos** (Secci√≥n 6.3.4):
- Enfoque: Comportamiento en tiempo de ejecuci√≥n, concurrencia, throughput
- Audiencia: Arquitectos de rendimiento, ingenieros de escalabilidad
- Artefactos: Diagramas de flujo de datos, diagramas de secuencia
- Notaci√≥n: Diagramas de actividad, BPMN adaptado

Cada vista se complementa con las dem√°s para formar una especificaci√≥n arquitect√≥nica completa. La Secci√≥n 6.3.5 sintetiza estas perspectivas y muestra c√≥mo se integran para formar el sistema completo.

---

### **6.3.2 Vista L√≥gica: Componentes y Patrones Arquitect√≥nicos**

La vista l√≥gica describe la descomposici√≥n funcional del sistema en servicios especializados y los patrones arquitect√≥nicos que gobiernan sus interacciones. Esta secci√≥n presenta la arquitectura h√≠brida implementada, detalla cada uno de los siete servicios que componen el sistema, y especifica los dos patrones de comunicaci√≥n fundamentales que coordinan sus operaciones.

#### **6.3.2.1 Patr√≥n H√≠brido Implementado**

El sistema implementa una **arquitectura h√≠brida** que combina tres patrones arquitect√≥nicos complementarios para satisfacer requisitos duales de latencia: operaciones s√≠ncronas de baja latencia (<1 segundo) para consultas de usuarios, y procesamiento as√≠ncrono distribuido de tareas computacionalmente intensivas que pueden requerir minutos u horas.

La Figura 6.X presenta la arquitectura h√≠brida completa, destacando los tres patrones integrados:

**[INSERTAR AQU√ç: architecture_diagram.png]**
*Figura 6.X: Arquitectura H√≠brida del Observatorio de Demanda Laboral. El sistema integra tres patrones: (1) API Gateway (Nginx) como punto √∫nico de entrada, (2) Microservicios en Capas (Frontend + API + PostgreSQL) para operaciones s√≠ncronas Request/Response, y (3) Event-Driven Architecture (Redis + Celery) para procesamiento as√≠ncrono distribuido mediante patr√≥n Pub/Sub.*

**Patr√≥n 1: API Gateway**

El patr√≥n API Gateway se implementa mediante Nginx, que act√∫a como punto √∫nico de entrada para todas las peticiones HTTP/HTTPS externas. Este patr√≥n proporciona:

- **Routing inteligente**: Enruta `/` hacia el servicio Frontend (puerto 3000) y `/api/*` hacia el servicio API (puerto 8000)
- **SSL/TLS termination**: Centraliza el manejo de certificados HTTPS, desencriptando tr√°fico antes de enrutarlo a servicios internos
- **Load balancing**: Distribuye carga entre m√∫ltiples instancias de servicios (configuraci√≥n futura)
- **Rate limiting**: Protege contra abuso y ataques de denegaci√≥n de servicio
- **Compresi√≥n gzip**: Reduce tama√±o de respuestas HTTP
- **Logging centralizado**: Registra todas las peticiones para auditor√≠a y debugging

**Patr√≥n 2: Microservicios en Capas (Request/Response)**

Para operaciones que requieren respuesta inmediata, se implementa una arquitectura de microservicios en tres capas:

- **Capa de Presentaci√≥n**: Frontend (Next.js) - Renderizado Server-Side (SSR) y gesti√≥n de interfaz de usuario
- **Capa de L√≥gica de Negocio**: API (FastAPI) - Endpoints REST, validaci√≥n, coordinaci√≥n de servicios
- **Capa de Persistencia**: PostgreSQL - Almacenamiento ACID de datos estructurados

Este patr√≥n se emplea para casos de uso que requieren latencias <1 segundo:
- Consultas de ofertas laborales filtradas por pa√≠s/fecha
- Estad√≠sticas agregadas (skills m√°s demandadas, tendencias)
- Consulta de estado de tareas as√≠ncronas (polling)
- Operaciones CRUD de administraci√≥n

**Patr√≥n 3: Event-Driven Architecture (Pub/Sub)**

Para operaciones computacionalmente intensivas que no requieren respuesta inmediata, se implementa arquitectura orientada a eventos mediante el patr√≥n Publisher/Subscriber:

- **Publishers**: API publica tareas a queue cuando recibe peticiones de procesamiento batch; Celery Beat publica tareas programadas (scraping cada 6 horas)
- **Message Queue**: Redis act√∫a como broker de mensajes, almacenando tareas pendientes y resultados
- **Subscribers**: Celery Workers consumen tareas de la queue, ejecutan procesamiento, y persisten resultados en PostgreSQL

Este patr√≥n se emplea para casos de uso que requieren minutos/horas de procesamiento:
- Scraping autom√°tico de 8 portales de empleo (10-60 minutos)
- Extracci√≥n de habilidades con LLM en batch (5 segundos √ó N jobs)
- Limpieza masiva de datos (10,000+ registros)
- Clustering de habilidades con UMAP + HDBSCAN (2-5 minutos para 10,000 skills)

**Justificaci√≥n de la Arquitectura H√≠brida**

La selecci√≥n de una arquitectura h√≠brida se fundament√≥ en cinco razones principales:

1. **Dualidad de requisitos de latencia**: Consultas de usuarios requieren <1s, procesamiento de datos requiere minutos/horas
2. **Escalabilidad horizontal selectiva**: Workers pueden escalarse din√°micamente (1‚ÜíN) sin modificar c√≥digo
3. **Simplicidad operativa con potencia de procesamiento**: Mantiene trazabilidad de sistemas modulares mientras obtiene paralelismo de sistemas distribuidos
4. **Optimizaci√≥n de recursos**: Request/Response evita overhead para operaciones simples; Event-Driven maximiza CPU/GPU para procesamiento intensivo
5. **Madurez del ecosistema**: Celery + Redis es combinaci√≥n probada industrialmente con amplia documentaci√≥n

**Comparaci√≥n con Alternativas Arquitect√≥nicas**

La Tabla 6.X presenta la evaluaci√≥n de tres estilos arquitect√≥nicos considerados:

**[INSERTAR AQU√ç: Tabla comparativa - puedes crearla basada en la que ya tenemos]**

| Criterio | Pipeline Lineal | Microservicios Puros | Arquitectura H√≠brida (Seleccionada) |
|----------|----------------|---------------------|-------------------------------------|
| Complejidad implementaci√≥n | Baja | Alta | Media |
| Escalabilidad horizontal | Limitada | Excelente | Excelente (workers) |
| Latencia consultas | Alta (bloqueante) | Baja | Baja (<1s) |
| Throughput procesamiento | Bajo (secuencial) | Medio | Alto (paralelo) |
| Trazabilidad | Excelente | Media | Alta |
| Tolerancia a fallos | Baja | Alta | Alta |
| Time to market | R√°pido | Lento | Medio |

*Tabla 6.X: Comparaci√≥n de estilos arquitect√≥nicos evaluados. La arquitectura h√≠brida combina ventajas de microservicios (escalabilidad, tolerancia a fallos) con eficiencia operativa de sistemas m√°s simples.*

El pipeline lineal fue descartado por impedir paralelismo y limitar throughput. Los microservicios puros fueron descartados por introducir complejidad innecesaria para un proyecto acad√©mico con equipo de 2 desarrolladores. La arquitectura h√≠brida proporciona el balance √≥ptimo entre capacidades t√©cnicas y viabilidad operativa.

#### **6.3.2.2 Los Siete Servicios del Sistema**

La arquitectura se descompone en siete servicios especializados, cada uno con responsabilidades claramente delimitadas. La Figura 6.Y presenta la vista de contenedores (C4 Model) que detalla cada servicio con sus tecnolog√≠as espec√≠ficas:

**[INSERTAR AQU√ç: architecture_c4_container.png]**
*Figura 6.Y: Vista de Contenedores (C4 Model - Container Level). Cada contenedor representa un servicio independiente con tecnolog√≠a espec√≠fica, puerto de comunicaci√≥n, y conexiones con otros servicios.*

Los siete servicios se describen a continuaci√≥n:

**1. NGINX - API Gateway**

**Responsabilidades**:
- Punto √∫nico de entrada HTTP/HTTPS
- Routing de peticiones a servicios apropiados
- Terminaci√≥n SSL/TLS
- Compresi√≥n y caching de respuestas

**Tecnolog√≠a**: nginx:alpine (imagen Docker oficial)
**Puerto**: 80 (HTTP), 443 (HTTPS)

**Configuraci√≥n de routing**:
```nginx
server {
    listen 80;
    server_name observatorio-laboral.com;
    
    # Redirigir HTTP a HTTPS
    return 301 https://$server_name$request_uri;
}

server {
    listen 443 ssl;
    server_name observatorio-laboral.com;
    
    ssl_certificate /etc/nginx/ssl/cert.pem;
    ssl_certificate_key /etc/nginx/ssl/key.pem;
    
    # Frontend - Interfaz de usuario
    location / {
        proxy_pass http://frontend:3000;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
    }
    
    # API - Endpoints REST
    location /api/ {
        proxy_pass http://api:8000;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    }
    
    # Compresi√≥n gzip
    gzip on;
    gzip_types text/plain application/json application/javascript text/css;
}
```

**2. Frontend - Interfaz de Usuario**

**Responsabilidades**:
- Renderizado de p√°ginas web (Server-Side Rendering)
- Gesti√≥n de estado de aplicaci√≥n (React)
- Visualizaci√≥n de dashboards y estad√≠sticas
- Polling para monitoreo de tareas as√≠ncronas

**Tecnolog√≠a**: Next.js 14, React 18, TypeScript, Tailwind CSS
**Puerto**: 3000 (interno, accesible v√≠a Nginx en `/`)

**Patr√≥n de comunicaci√≥n con API**:

*Request/Response s√≠ncrono* (consultas r√°pidas):
```typescript
// Consulta de ofertas laborales
const response = await fetch('/api/jobs?country=CO&limit=10');
const data = await response.json();
// Respuesta en <1 segundo
```

*Request/Response as√≠ncrono con polling* (procesamiento batch):
```typescript
// 1. Solicitar procesamiento de 100 jobs
const response = await fetch('/api/extract/batch', {
    method: 'POST',
    body: JSON.stringify({ job_ids: Array.from({length:100}, (_, i) => i+1) })
});
const { task_id } = await response.json(); // Respuesta inmediata con task_id

// 2. Polling cada 3 segundos para monitorear progreso
const interval = setInterval(async () => {
    const statusResponse = await fetch(`/api/tasks/${task_id}`);
    const { state, progress } = await statusResponse.json();
    
    if (state === 'SUCCESS') {
        clearInterval(interval);
        // Mostrar resultados
    } else {
        // Actualizar barra de progreso: progress%
    }
}, 3000);
```

**3. API - L√≥gica de Negocio**

**Responsabilidades**:
- Exponer endpoints REST para operaciones CRUD
- Validar datos de entrada (Pydantic)
- Coordinar servicios (Publisher de tareas as√≠ncronas)
- Consultar estado de tareas en Redis
- Implementar l√≥gica de negocio

**Tecnolog√≠a**: FastAPI 0.104+, Python 3.11+, Pydantic v2, SQLAlchemy
**Puerto**: 8000 (interno, accesible v√≠a Nginx en `/api/*`)

**Funcionalidad dual**:

El servicio API implementa dos patrones de comunicaci√≥n seg√∫n el tipo de operaci√≥n:

*Patr√≥n Request/Response s√≠ncrono*:
```python
@app.get("/api/jobs")
async def get_jobs(country: str = Query(...), limit: int = 10):
    """Consulta r√°pida de ofertas laborales (<1s)."""
    jobs = db.query(RawJob)\
             .filter_by(country=country)\
             .limit(limit)\
             .all()
    
    return {
        "jobs": [job.to_dict() for job in jobs],
        "total": len(jobs)
    }
```

*Patr√≥n Pub/Sub as√≠ncrono*:
```python
@app.post("/api/extract/batch")
async def extract_batch(job_ids: List[int], pipeline: str):
    """
    Procesamiento as√≠ncrono de extracci√≥n de habilidades.
    Responde INMEDIATAMENTE con task_ids, procesamiento ocurre en background.
    """
    task_ids = []
    
    for job_id in job_ids:
        # Publica tarea a Redis queue (NO espera resultado)
        task = extract_skills_task.delay(job_id, pipeline)
        task_ids.append(task.id)
    
    # Respuesta inmediata (<100ms)
    return {
        "batch_id": f"batch_{uuid.uuid4()}",
        "task_ids": task_ids,
        "status": "QUEUED",
        "total": len(job_ids)
    }

@app.get("/api/tasks/{task_id}")
async def get_task_status(task_id: str):
    """Consulta estado de tarea as√≠ncrona (polling desde Frontend)."""
    result = AsyncResult(task_id, app=celery_app)
    
    return {
        "task_id": task_id,
        "state": result.state,  # PENDING, STARTED, SUCCESS, FAILURE
        "progress": result.info.get('progress', 0) if result.info else 0,
        "result": result.result if result.successful() else None,
        "error": str(result.info) if result.failed() else None
    }
```

**Endpoints principales**:
- `GET /api/jobs` - Lista ofertas laborales (filtros: pa√≠s, fecha, estado)
- `GET /api/stats` - Estad√≠sticas agregadas (skills por pa√≠s, tendencias temporales)
- `GET /api/skills` - Habilidades extra√≠das (con normalizaci√≥n ESCO)
- `GET /api/clusters` - Resultados de clustering (m√©tricas, etiquetas)
- `POST /api/admin/scrape` - Trigger manual de scraping
- `POST /api/extract/batch` - Extracci√≥n batch con LLM (as√≠ncrono)
- `POST /api/jobs/clean/batch` - Limpieza masiva (as√≠ncrono)
- `GET /api/tasks/{task_id}` - Estado de tarea as√≠ncrona

**4. PostgreSQL - Base de Datos**

**Responsabilidades**:
- Persistencia ACID de datos estructurados
- Almacenamiento de embeddings 768D (extensi√≥n pgvector)
- Garantizar trazabilidad mediante relaciones foreign key
- Optimizaci√≥n de consultas mediante √≠ndices

**Tecnolog√≠a**: PostgreSQL 15+, extensi√≥n pgvector 0.5+
**Puerto**: 5433 (host) ‚Üí 5432 (contenedor)

El dise√±o de base de datos se detalla en la Secci√≥n 6.3.6.

**5. Redis - Message Queue y Cache**

**Responsabilidades**:
- Cola de mensajes para patr√≥n Pub/Sub (Celery broker)
- Almacenamiento de resultados de tareas (Celery result backend)
- Cache de queries frecuentes (TTL configurable)
- Gesti√≥n de estado de tareas

**Tecnolog√≠a**: Redis 7.x (imagen Docker oficial)
**Puerto**: 6379

**Configuraci√≥n como broker de Celery**:
```python
# settings.py
CELERY_BROKER_URL = 'redis://redis:6379/0'
CELERY_RESULT_BACKEND = 'redis://redis:6379/1'
CELERY_RESULT_EXPIRES = 86400  # 24 horas
```

**Uso como cache**:
```python
import redis
import json

redis_client = redis.Redis(host='redis', port=6379, db=2)

@app.get("/api/stats")
async def get_stats(country: str):
    cache_key = f"stats:{country}"
    
    # Intenta obtener de cache
    cached = redis_client.get(cache_key)
    if cached:
        return json.loads(cached)
    
    # Si no existe, consulta DB
    stats = compute_stats(country)  # Consulta costosa a PostgreSQL
    
    # Almacena en cache (TTL 5 minutos)
    redis_client.setex(cache_key, 300, json.dumps(stats))
    
    return stats
```

**6. Celery Beat - Programador de Tareas**

**Responsabilidades**:
- Programar tareas peri√≥dicas (cron-like)
- Publicar tareas programadas a Redis queue
- Gestionar schedules de scraping autom√°tico

**Tecnolog√≠a**: Celery 5.x, Python 3.11+
**Puerto**: N/A (no expone puertos)

**Configuraci√≥n de tareas peri√≥dicas**:
```python
from celery.schedules import crontab

app.conf.beat_schedule = {
    # Scraping cada 6 horas
    'scrape-all-portals': {
        'task': 'tasks.scrape_all_portals',
        'schedule': crontab(hour='*/6'),
    },
    # Limpieza de datos antiguos (diaria a las 3 AM)
    'clean-old-data': {
        'task': 'tasks.clean_old_jobs',
        'schedule': crontab(hour=3, minute=0),
    },
    # Recalculo de estad√≠sticas (semanal, lunes 8 AM)
    'update-statistics': {
        'task': 'tasks.update_statistics',
        'schedule': crontab(hour=8, minute=0, day_of_week=1),
    },
}
```

**7. Celery Workers - Procesadores Distribuidos**

**Responsabilidades**:
- Consumir tareas de Redis queue
- Ejecutar pipeline CRISP-DM de procesamiento de datos
- Procesar tareas en paralelo (m√∫ltiples workers)
- Persistir resultados en PostgreSQL
- Reportar progreso de tareas

**Tecnolog√≠a**: Celery 5.x, Python 3.11+, con soporte GPU (CUDA) si disponible
**Puerto**: N/A (no expone puertos)

**Escalabilidad horizontal**:

Los workers pueden escalarse din√°micamente sin cambios de c√≥digo:

```bash
# Iniciar con 1 worker
docker-compose up -d celery_worker

# Escalar a 8 workers (8x throughput te√≥rico)
docker-compose up -d --scale celery_worker=8

# Sin cambios de c√≥digo, sin reconfiguraci√≥n
# Load balancing autom√°tico por Redis
```

**Ejemplo de throughput**:
- 1 worker: 100 jobs √ó 5s = 500 segundos (8 min 20 seg)
- 4 workers: 100 jobs √∑ 4 = 125 segundos (2 min 5 seg)
- 8 workers: 100 jobs √∑ 8 = 62.5 segundos (1 min 2 seg)

**Tareas procesadas por workers**:
1. Scraping de portales (Scrapy + Selenium): 5-10 min por portal
2. Extracci√≥n NER+Regex (spaCy): 100-200ms por job
3. Procesamiento LLM (Gemma 3 4B): 2-5s por job
4. Normalizaci√≥n ESCO (fuzzy matching): 50-100ms por skill
5. Generaci√≥n embeddings (E5 multilingual): 100ms/batch de 32
6. Clustering (UMAP + HDBSCAN): 2-5 min para 10K skills

#### **6.3.2.3 Patrones de Comunicaci√≥n: Request/Response y Pub/Sub**

El sistema emplea dos patrones fundamentales de comunicaci√≥n seg√∫n requisitos de latencia:

**Patr√≥n Request/Response (S√≠ncrono)**

```
Usuario ‚Üí Frontend ‚Üí API ‚Üí PostgreSQL ‚Üí API ‚Üí Frontend ‚Üí Usuario
Tiempo: <1 segundo
```

**Casos de uso**:
- Consultas de datos ya procesados
- Estad√≠sticas agregadas
- Operaciones CRUD de administraci√≥n
- Polling de estado de tareas

**Ventajas**:
- Latencia predecible y baja
- Simplicidad de implementaci√≥n
- F√°cil debugging y trazabilidad

**Patr√≥n Pub/Sub (As√≠ncrono)**

```
API/Beat ‚Üí Redis Queue ‚Üí Workers (1...N) ‚Üí PostgreSQL
Frontend ‚Üí API: Polling GET /api/tasks/{id} cada 3s
Tiempo: Variable (procesamiento en background)
```

**Casos de uso**:
- Scraping autom√°tico programado
- Extracci√≥n batch con LLM (100+ jobs)
- Limpieza masiva de datos (10K+ registros)
- Clustering de habilidades

**Ventajas**:
- No bloquea al usuario (respuesta inmediata)
- Procesamiento paralelo distribuido
- Escalabilidad horizontal
- Tolerancia a fallos (reintentos autom√°ticos)

**Decisi√≥n de qu√© patr√≥n usar**:

La decisi√≥n se basa en tiempo estimado de procesamiento:

- Operaci√≥n estimada <5 segundos ‚Üí Request/Response s√≠ncrono
- Operaci√≥n estimada >5 segundos ‚Üí Pub/Sub as√≠ncrono con polling

---

### **6.3.3 Vista F√≠sica: Infraestructura y Despliegue**

La vista f√≠sica describe el mapeo de componentes l√≥gicos sobre infraestructura f√≠sica, especificando hardware, contenedores Docker, configuraci√≥n de red, y estrategia de despliegue. Esta secci√≥n detalla la topolog√≠a de deployment que materializa la arquitectura l√≥gica presentada en la secci√≥n anterior.

**[INSERTAR AQU√ç: architecture_physical_view.png]**
*Figura 6.Z: Vista F√≠sica / Deployment View. El diagrama muestra el servidor de producci√≥n con especificaciones de hardware, los 10 contenedores Docker orquestados por Docker Compose, mapeo de puertos, red bridge interna, y vol√∫menes persistentes.*

#### **6.3.3.1 Especificaciones del Servidor**

El sistema se despliega en un servidor √∫nico que ejecuta todos los servicios mediante contenedores Docker. Las especificaciones m√≠nimas recomendadas son:

**Hardware / Virtual Machine**:
- **Sistema Operativo**: Ubuntu Server 24.04 LTS
- **CPU**: 8 cores @ 2.4 GHz (Intel Xeon o AMD EPYC)
- **RAM**: 16 GB DDR4
- **Storage**: 500 GB SSD (NVMe recomendado)
- **Network**: 1 Gbps
- **GPU** (opcional): NVIDIA con 8GB VRAM para aceleraci√≥n de LLM inference

**Software Base**:
- Docker Engine 24.0+
- Docker Compose v2
- NVIDIA Container Toolkit (si se usa GPU)

**Firewall**:
- Puertos abiertos: 80 (HTTP), 443 (HTTPS)
- Todos los dem√°s puertos bloqueados externamente
- Comunicaci√≥n interna entre contenedores v√≠a red Docker

#### **6.3.3.2 Contenedores Docker y Orquestaci√≥n**

El sistema se compone de 10 contenedores Docker orquestados mediante Docker Compose:

**Contenedores de Servicios Principales** (5):

| Servicio | Imagen | Puerto Host‚ÜíContainer | CPU | RAM | Volumen |
|----------|--------|----------------------|-----|-----|---------|
| nginx | nginx:alpine | 80‚Üí80, 443‚Üí443 | 1 | 1 GB | - |
| frontend | frontend:latest | 3000‚Üí3000 | 1 | 1 GB | - |
| api | api:latest | 8000‚Üí8000 | 1 | 1 GB | - |
| postgres | postgres:15 | 5433‚Üí5432 | 2 | 4 GB | postgres_data (100GB) |
| redis | redis:7-alpine | 6379‚Üí6379 | 1 | 2 GB | redis_data (10GB) |

**Contenedores de Procesamiento** (5):

| Servicio | Imagen | Puerto | CPU | RAM | GPU | Escalable |
|----------|--------|--------|-----|-----|-----|-----------|
| celery_beat | celery:latest | N/A | 0.5 | 512 MB | No | No |
| celery_worker | celery:latest | N/A | 2 | 4 GB | S√≠ (opcional) | **S√≠ (1‚ÜíN)** |

**Nota**: `celery_worker` puede replicarse din√°micamente (1, 2, 4, 8, ... N instancias) sin cambios de c√≥digo mediante el comando:
```bash
docker-compose up -d --scale celery_worker=N
```

**Configuraci√≥n Docker Compose**:

El archivo `docker-compose.yml` orquesta todos los servicios:

```yaml
version: '3.8'

services:
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/ssl:/etc/nginx/ssl:ro
    networks:
      - labor_observatory_network
    depends_on:
      - frontend
      - api
    restart: unless-stopped

  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    image: frontend:latest
    ports:
      - "3000:3000"
    environment:
      - NODE_ENV=production
      - NEXT_PUBLIC_API_URL=http://api:8000
    networks:
      - labor_observatory_network
    restart: unless-stopped

  api:
    build:
      context: ./api
      dockerfile: Dockerfile.api
    image: api:latest
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=postgresql://postgres:${DB_PASSWORD}@postgres:5432/labor_observatory
      - REDIS_URL=redis://redis:6379
      - CELERY_BROKER_URL=redis://redis:6379/0
      - CELERY_RESULT_BACKEND=redis://redis:6379/1
    networks:
      - labor_observatory_network
    depends_on:
      - postgres
      - redis
    restart: unless-stopped

  postgres:
    image: postgres:15
    ports:
      - "5433:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    environment:
      - POSTGRES_DB=labor_observatory
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=${DB_PASSWORD}
    networks:
      - labor_observatory_network
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 4G
    restart: unless-stopped

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    networks:
      - labor_observatory_network
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 2G
    restart: unless-stopped

  celery_beat:
    build:
      context: ./api
      dockerfile: Dockerfile.api
    image: celery:latest
    command: celery -A tasks beat --loglevel=info
    environment:
      - DATABASE_URL=postgresql://postgres:${DB_PASSWORD}@postgres:5432/labor_observatory
      - REDIS_URL=redis://redis:6379
      - CELERY_BROKER_URL=redis://redis:6379/0
    networks:
      - labor_observatory_network
    depends_on:
      - redis
      - postgres
    restart: unless-stopped

  celery_worker:
    build:
      context: ./api
      dockerfile: Dockerfile.api
    image: celery:latest
    command: celery -A tasks worker --loglevel=info --concurrency=2
    environment:
      - DATABASE_URL=postgresql://postgres:${DB_PASSWORD}@postgres:5432/labor_observatory
      - REDIS_URL=redis://redis:6379
      - CELERY_BROKER_URL=redis://redis:6379/0
      - CELERY_RESULT_BACKEND=redis://redis:6379/1
    networks:
      - labor_observatory_network
    depends_on:
      - redis
      - postgres
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 4G
    restart: unless-stopped

networks:
  labor_observatory_network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.18.0.0/16
          gateway: 172.18.0.1

volumes:
  postgres_data:
    driver: local
  redis_data:
    driver: local
  logs_data:
    driver: local
```

#### **6.3.3.3 Configuraci√≥n de Red y Vol√∫menes**

**Red Docker (Bridge)**:

Todos los contenedores se conectan a una red bridge interna que proporciona:

- **Subnet**: 172.18.0.0/16 (65,536 direcciones IP disponibles)
- **Gateway**: 172.18.0.1
- **DNS interno**: Resoluci√≥n autom√°tica por nombre de servicio
  - Ejemplo: `postgres` resuelve autom√°ticamente a IP del contenedor PostgreSQL
  - Ejemplo: `http://api:8000` es accesible desde frontend sin conocer IP

**Aislamiento de red**:
- Contenedores solo pueden comunicarse entre s√≠ dentro de la red
- Solo nginx expone puertos externamente (80, 443)
- PostgreSQL y Redis no son accesibles desde fuera del servidor

**Vol√∫menes Persistentes**:

Los datos que deben persistir entre reinicios de contenedores se almacenan en vol√∫menes Docker:

| Volumen | Mount Point | Tama√±o | Contenido |
|---------|------------|--------|-----------|
| postgres_data | /var/lib/postgresql/data | 100 GB | Base de datos completa |
| redis_data | /data | 10 GB | Dumps de Redis, snapshots |
| logs_data | /var/log | 20 GB | Logs de todos los servicios |

**Estrategia de backup**:
- Backup diario de `postgres_data` mediante pg_dump
- Snapshots de vol√∫menes Docker semanalmente
- Logs rotados cada 7 d√≠as, comprimidos y archivados

---

### **6.3.4 Vista de Procesos: Ejecuci√≥n y Concurrencia**

La vista de procesos describe el comportamiento din√°mico del sistema en tiempo de ejecuci√≥n, abordando aspectos de concurrencia, distribuci√≥n de procesamiento, throughput, y escalabilidad. Esta secci√≥n presenta el pipeline CRISP-DM que ejecutan los workers, la estrategia de escalamiento horizontal, y la gesti√≥n de tareas as√≠ncronas.

#### **6.3.4.1 Pipeline CRISP-DM y Flujo de Procesamiento**

El procesamiento de datos sigue la metodolog√≠a CRISP-DM (Cross-Industry Standard Process for Data Mining) adaptada al dominio de an√°lisis de mercado laboral. El pipeline se compone de 7 etapas secuenciales ejecutadas por los Celery Workers:

**[INSERTAR AQU√ç: Diagrama del pipeline CRISP-DM si lo tienes, o la parte inferior de architecture_diagram.png]**

**Etapa 1: Scraping**
- **Entrada**: URLs de portales de empleo (8 portales √ó 3 pa√≠ses)
- **Proceso**: Scrapy + Selenium para recolecci√≥n automatizada
- **Salida**: Raw jobs almacenados en tabla `raw_jobs`
- **Tiempo**: 5-10 minutos por portal
- **Deduplicaci√≥n**: Hash SHA-256 de (t√≠tulo + empresa + ubicaci√≥n + fecha)

**Etapa 2: Cleaning**
- **Entrada**: Raw jobs de tabla `raw_jobs`
- **Proceso**: Normalizaci√≥n de texto, eliminaci√≥n de HTML, detecci√≥n de idioma
- **Salida**: Cleaned jobs en tabla `cleaned_jobs` con campo `is_usable`
- **Tiempo**: 50-100ms por job

**Etapa 3: Extraction**
- **Entrada**: Cleaned jobs
- **Proceso**: **Aqu√≠ se usan los Pipelines A o B** (NER+Regex vs LLM)
- **Salida**: Extracted skills en tabla `extracted_skills`
- **Tiempo**: 100-200ms (Pipeline A) o 2-5s (Pipeline B) por job

**Nota importante**: Los Pipelines A y B son **variantes experimentales de esta etapa**. No son arquitecturas separadas, sino m√©todos alternativos de extracci√≥n comparados en el Cap√≠tulo 8 (Resultados).

**Etapa 4: Enhancement**
- **Entrada**: Extracted skills
- **Proceso**: Normalizaci√≥n con LLM, inferencia de skills impl√≠citas, mapeo a ESCO
- **Salida**: Enhanced skills en tabla `enhanced_skills`
- **Tiempo**: 1-3s por job

**Etapa 5: Embedding**
- **Entrada**: Enhanced skills (texto normalizado)
- **Proceso**: Generaci√≥n de embeddings 768D con modelo E5-multilingual
- **Salida**: Vectores en tabla `skill_embeddings` (pgvector)
- **Tiempo**: 100ms por batch de 32 skills

**Etapa 6: Clustering**
- **Entrada**: Skill embeddings (10,000+ vectores 768D)
- **Proceso**: Reducci√≥n UMAP (768D ‚Üí 2D/3D), clustering HDBSCAN
- **Salida**: Clusters con etiquetas en tabla `clustering_results`
- **Tiempo**: 2-5 minutos para 10K skills

**Etapa 7: Visualization**
- **Entrada**: Clustering results
- **Proceso**: Generaci√≥n de gr√°ficos (scatter plots, heatmaps, tendencias temporales)
- **Salida**: Im√°genes PNG, datos JSON para frontend
- **Tiempo**: 10-30 segundos

**Ejecuci√≥n del pipeline completo**:

```python
@celery_app.task(bind=True)
def process_job_complete_pipeline(self, job_id: int):
    """
    Ejecuta pipeline CRISP-DM completo para un job.
    Reporta progreso a trav√©s de self.update_state().
    """
    # Etapa 1-2: Ya realizadas (Scraping + Cleaning)
    job = db.query(RawJob).filter_by(id=job_id).first()
    
    # Etapa 3: Extraction (usa Pipeline A o B seg√∫n configuraci√≥n)
    self.update_state(state='STARTED', meta={'stage': 'extraction', 'progress': 20})
    skills = extract_skills(job, pipeline=settings.EXTRACTION_PIPELINE)
    
    # Etapa 4: Enhancement
    self.update_state(state='STARTED', meta={'stage': 'enhancement', 'progress': 40})
    enhanced_skills = enhance_skills(skills)
    
    # Etapa 5: Embedding
    self.update_state(state='STARTED', meta={'stage': 'embedding', 'progress': 60})
    embeddings = generate_embeddings(enhanced_skills)
    
    # Etapa 6: Clustering (solo si es el √∫ltimo job del batch)
    if is_last_job_in_batch(job_id):
        self.update_state(state='STARTED', meta={'stage': 'clustering', 'progress': 80})
        clusters = perform_clustering(embeddings)
        
        # Etapa 7: Visualization
        self.update_state(state='STARTED', meta={'stage': 'visualization', 'progress': 90})
        visualizations = create_visualizations(clusters)
    
    return {
        'job_id': job_id,
        'skills_extracted': len(skills),
        'skills_enhanced': len(enhanced_skills),
        'status': 'completed'
    }
```

#### **6.3.4.2 Escalabilidad Horizontal de Workers**

La arquitectura permite escalamiento horizontal din√°mico de workers sin modificar c√≥digo ni reconfigurar servicios:

**Comando de escalamiento**:
```bash
docker-compose up -d --scale celery_worker=N
```

**Ejemplo de escalamiento 1‚Üí8 workers**:

```bash
# Estado inicial: 1 worker
$ docker-compose ps
NAME                  IMAGE            STATUS
celery_worker_1       celery:latest    Up

# Escalar a 8 workers
$ docker-compose up -d --scale celery_worker=8

# Nuevo estado: 8 workers en paralelo
$ docker-compose ps
NAME                  IMAGE            STATUS
celery_worker_1       celery:latest    Up
celery_worker_2       celery:latest    Up
celery_worker_3       celery:latest    Up
celery_worker_4       celery:latest    Up
celery_worker_5       celery:latest    Up
celery_worker_6       celery:latest    Up
celery_worker_7       celery:latest    Up
celery_worker_8       celery:latest    Up
```

**Load balancing autom√°tico**:

Redis distribuye tareas equitativamente entre workers disponibles:

```
Redis Queue (100 tareas pendientes)
    ‚îú‚îÄ‚îÄ Worker 1: Procesa tareas [1, 9, 17, 25, ...]   (~12 tareas)
    ‚îú‚îÄ‚îÄ Worker 2: Procesa tareas [2, 10, 18, 26, ...]  (~12 tareas)
    ‚îú‚îÄ‚îÄ Worker 3: Procesa tareas [3, 11, 19, 27, ...]  (~12 tareas)
    ‚îú‚îÄ‚îÄ Worker 4: Procesa tareas [4, 12, 20, 28, ...]  (~12 tareas)
    ‚îú‚îÄ‚îÄ Worker 5: Procesa tareas [5, 13, 21, 29, ...]  (~13 tareas)
    ‚îú‚îÄ‚îÄ Worker 6: Procesa tareas [6, 14, 22, 30, ...]  (~13 tareas)
    ‚îú‚îÄ‚îÄ Worker 7: Procesa tareas [7, 15, 23, 31, ...]  (~13 tareas)
    ‚îî‚îÄ‚îÄ Worker 8: Procesa tareas [8, 16, 24, 32, ...]  (~13 tareas)
```

**Impacto en throughput**:

| Workers | Tareas Totales | Tiempo Promedio por Tarea | Tiempo Total | Speedup |
|---------|----------------|---------------------------|--------------|---------|
| 1 | 100 | 5s | 500s (8 min 20s) | 1x |
| 2 | 100 | 5s | 250s (4 min 10s) | 2x |
| 4 | 100 | 5s | 125s (2 min 5s) | 4x |
| 8 | 100 | 5s | 62.5s (1 min 2s) | 8x |

*Nota*: Speedup te√≥rico asume tareas independientes sin contenci√≥n de recursos (CPU, DB, Redis). En pr√°ctica, speedup real es ~0.7√óN debido a overhead de comunicaci√≥n y contenci√≥n.

**Tolerancia a fallos**:

Si un worker falla, los dem√°s contin√∫an procesando:

```bash
# Worker 3 falla (simulaci√≥n)
$ docker stop labor_observatory_celery_worker_3

# Redis redistribuye tareas pendientes a workers restantes
# Workers 1, 2, 4, 5, 6, 7, 8 contin√∫an procesando
# Tarea que estaba ejecutando Worker 3 se reintenta en otro worker
```

**Reintentos autom√°ticos**:

```python
@celery_app.task(bind=True, max_retries=3, default_retry_delay=60)
def extract_skills_task(self, job_id: int):
    try:
        # Procesamiento
        result = extract_skills(job_id)
        return result
    except Exception as exc:
        # Reintenta hasta 3 veces con delay de 60s
        raise self.retry(exc=exc, countdown=60)
```

#### **6.3.4.3 Gesti√≥n de Tareas As√≠ncronas**

**Ciclo de vida de una tarea**:

```
1. QUEUED    ‚Üí Tarea publicada a Redis queue
2. PENDING   ‚Üí Tarea en queue, esperando worker disponible
3. STARTED   ‚Üí Worker tom√≥ la tarea, comenz√≥ procesamiento
4. PROGRESS  ‚Üí Worker reporta progreso (20%, 40%, 60%, ...)
5. SUCCESS   ‚Üí Tarea completada exitosamente, resultado disponible
   o
   FAILURE   ‚Üí Tarea fall√≥, error almacenado
```

**Monitoreo desde Frontend**:

```typescript
interface TaskStatus {
    task_id: string;
    state: 'PENDING' | 'STARTED' | 'SUCCESS' | 'FAILURE';
    progress: number;  // 0-100
    result: any;
    error: string | null;
}

async function monitorTask(taskId: string): Promise<void> {
    const interval = setInterval(async () => {
        const response = await fetch(`/api/tasks/${taskId}`);
        const status: TaskStatus = await response.json();
        
        // Actualizar UI con progreso
        updateProgressBar(status.progress);
        updateStatusText(status.state);
        
        // Si complet√≥ (√©xito o fallo), detener polling
        if (status.state === 'SUCCESS') {
            clearInterval(interval);
            showResults(status.result);
        } else if (status.state === 'FAILURE') {
            clearInterval(interval);
            showError(status.error);
        }
    }, 3000);  // Polling cada 3 segundos
}
```

**M√©tricas de rendimiento**:

El sistema registra m√©tricas para cada tarea:
- Tiempo de espera en queue (QUEUED ‚Üí STARTED)
- Tiempo de ejecuci√≥n (STARTED ‚Üí SUCCESS/FAILURE)
- Tasa de √©xito/fallo
- Throughput (tareas/minuto)

Estas m√©tricas permiten optimizar n√∫mero de workers y detectar cuellos de botella.

---

### **6.3.5 Integraci√≥n de Vistas: Arquitectura Completa**

Las tres vistas arquitect√≥nicas se integran para formar una especificaci√≥n completa del sistema:

**Vista L√≥gica** proporciona la descomposici√≥n funcional en 7 servicios especializados que implementan tres patrones arquitect√≥nicos (API Gateway, Microservicios en Capas, Event-Driven).

**Vista F√≠sica** mapea estos servicios l√≥gicos sobre 10 contenedores Docker ejecut√°ndose en un servidor con especificaciones definidas, conectados por red bridge interna y persistiendo datos en vol√∫menes Docker.

**Vista de Procesos** describe el comportamiento din√°mico mediante el pipeline CRISP-DM de 7 etapas ejecutado por workers escalables horizontalmente, con gesti√≥n de tareas as√≠ncronas y m√©tricas de rendimiento.

**Mapeo entre vistas**:

| Vista L√≥gica (Servicio) | Vista F√≠sica (Container) | Vista de Procesos (Ejecuci√≥n) |
|------------------------|-------------------------|------------------------------|
| NGINX | nginx:alpine en puerto 80/443 | Enruta requests HTTP/HTTPS |
| Frontend | frontend:latest en puerto 3000 | Renderiza UI + Polling as√≠ncrono |
| API | api:latest en puerto 8000 | Publisher de tareas + Request/Response |
| PostgreSQL | postgres:15 con volumen 100GB | Persistencia ACID de datos |
| Redis | redis:7 con volumen 10GB | Message queue + Cache |
| Celery Beat | celery:latest sin puerto | Scheduler de tareas peri√≥dicas |
| Celery Workers | celery:latest √ó N (escalable) | Ejecuta pipeline CRISP-DM en paralelo |

**Flujo end-to-end completo**:

```
Usuario solicita procesamiento de 100 jobs:

[Vista L√≥gica]
  Usuario ‚Üí Frontend ‚Üí API ‚Üí Redis (publica 100 tareas)
  
[Vista F√≠sica]
  HTTPS:443 ‚Üí nginx:80 ‚Üí frontend:3000 ‚Üí api:8000 ‚Üí redis:6379
  
[Vista de Procesos]
  Workers (1-8) consumen tareas de Redis queue
  Cada worker ejecuta pipeline CRISP-DM (7 etapas)
  Resultados se persisten en PostgreSQL
  Frontend hace polling cada 3s para monitorear progreso
  
[Resultado]
  100 jobs procesados en 62-500s (seg√∫n N workers)
  Usuario ve resultados en dashboard
```

Esta integraci√≥n de vistas proporciona una especificaci√≥n arquitect√≥nica completa, no ambigua, y reproducible del sistema.

---

### **6.3.6 Dise√±o de la Base de Datos**

[MANTENER EL CONTENIDO EXISTENTE DE LA SECCI√ìN 6.3.3 "Dise√±o de la Base de Datos" DEL DOCUMENTO ORIGINAL]

[Aqu√≠ va el diagrama ER, las 6 tablas, las relaciones foreign key, etc. que ya tienes en tu documento]

---

## üìä Resumen de Cambios

### ‚ùå Eliminar del documento actual:
- Secci√≥n 6.3.1 "Selecci√≥n del Estilo Arquitect√≥nico" (descripci√≥n de pipeline lineal)
- Referencias a "arquitectura de pipeline lineal"
- Tabla 6.3 con comparaci√≥n incorrecta de arquitecturas
- Figura 6.1 si muestra pipeline lineal

### ‚úÖ Agregar al documento:
- Nueva secci√≥n 6.3.1 "Modelo de Vistas Arquitect√≥nicas"
- Nueva secci√≥n 6.3.2 "Vista L√≥gica" con subsecciones
- Nueva secci√≥n 6.3.3 "Vista F√≠sica" con subsecciones
- Nueva secci√≥n 6.3.4 "Vista de Procesos" con subsecciones
- Nueva secci√≥n 6.3.5 "Integraci√≥n de Vistas"
- Mantener secci√≥n 6.3.6 "Dise√±o de Base de Datos" (ya existente)

### üìê Diagramas a insertar:
1. **Figura 6.X**: architecture_diagram.png (Vista L√≥gica general)
2. **Figura 6.Y**: architecture_c4_container.png (Vista L√≥gica detallada)
3. **Figura 6.Z**: architecture_physical_view.png (Vista F√≠sica)
4. **Figura 6.W** (opcional): niveles_sistema_explicacion.png (Explicaci√≥n de niveles)

### üìè Tablas a crear:
1. **Tabla 6.X**: Comparaci√≥n de arquitecturas (con columna "Arquitectura H√≠brida")
2. **Tabla 6.Y**: Especificaciones de contenedores Docker
3. **Tabla 6.Z**: Distribuci√≥n de recursos (CPU/RAM)
4. **Tabla 6.W**: Ciclo de vida de tareas as√≠ncronas

---

## üéØ Instrucciones de Implementaci√≥n

1. **Backup**: Hacer copia de seguridad del documento main.pdf actual

2. **Reemplazar Secci√≥n 6.3 completa**: Usar el texto propuesto arriba

3. **Insertar diagramas** en las ubicaciones marcadas con [INSERTAR AQU√ç]

4. **Crear tablas** seg√∫n especificaciones (usar datos de los documentos MD)

5. **Actualizar √≠ndice** con nueva numeraci√≥n de subsecciones

6. **Revisar referencias cruzadas**: Si hay menciones a "pipeline lineal" en otros cap√≠tulos, actualizarlas a "arquitectura h√≠brida"

7. **Actualizar Abstract/Resumen**: Mencionar arquitectura h√≠brida en lugar de pipeline lineal

---

## üìã Checklist de Revisi√≥n

Antes de finalizar, verificar:

- [ ] Todas las figuras est√°n insertadas y numeradas correctamente
- [ ] Todas las tablas est√°n creadas y numeradas
- [ ] No quedan referencias a "pipeline lineal" como arquitectura
- [ ] Se explica claramente que Pipelines A/B son variantes de etapa "Extraction"
- [ ] √çndice actualizado con nueva estructura
- [ ] Referencias cruzadas funcionan correctamente
- [ ] Formato consistente (fonts, tama√±os, espaciado)
- [ ] Pie de p√°gina de figuras es descriptivo
- [ ] C√≥digo fuente tiene syntax highlighting si es posible

---

**Esta propuesta reemplaza completamente la secci√≥n 6.3 con documentaci√≥n arquitect√≥nica profesional siguiendo el modelo 4+1 de vistas, corrigiendo todos los errores identificados en el documento original.**
